{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a122adee9a39c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.757210Z",
     "start_time": "2024-08-21T17:56:54.457070Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad2373f64ed7deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.764952Z",
     "start_time": "2024-08-21T17:56:56.763360Z"
    }
   },
   "outputs": [],
   "source": [
    "# waveform function for me to not bang my keyboard\n",
    "def disp_waveform(signal, sr=None, color='blue'):\n",
    "    plt.figure(figsize=(7,2))\n",
    "    return librosa.display.waveshow(signal, sr=sr, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.767755Z",
     "start_time": "2024-08-21T17:56:56.765455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, n_fft, hop_length, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        disp_waveform(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        disp_waveform(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        disp_waveform(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*hop_length) + n_fft//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            # strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            # keystroke = transform(keystroke)\n",
    "            strokes.append(keystroke)\n",
    "            if show:\n",
    "                disp_waveform(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c33893a14fb819c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.814715Z",
     "start_time": "2024-08-21T17:56:56.768186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants we actually need for the task\n",
    "MBP_AUDIO_DIR = '../Dataset-for-Binary/base-audio/'\n",
    "keys_s = '1234567890QWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "# keys_s = '12'\n",
    "labels = list(keys_s)\n",
    "keys = ['audio_' + k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fee322473e2bfe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.817344Z",
     "start_time": "2024-08-21T17:56:56.815269Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_fft, hop_length, before, after):\n",
    "    for i, File in enumerate(keys):\n",
    "        loc = MBP_AUDIO_DIR + File\n",
    "        samples, sr = librosa.load(loc)\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        strokes = isolator(samples, sr, n_fft, hop_length, before, after, prom, False )\n",
    "        print(f'File {File} length: {len(strokes)}')\n",
    "        label = [labels[i]]*len(strokes)\n",
    "        data_dict['Key'] += label\n",
    "        data_dict['File'] += strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if not l in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953e2f0556453dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:58.565620Z",
     "start_time": "2024-08-21T17:56:56.817785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "26 22050\n",
      "25 22050\n",
      "25 22050\n",
      "27 22050\n",
      "26 22050\n",
      "27 22050\n",
      "28 22050\n",
      "28 22050\n",
      "25 22050\n",
      "26 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "27 22050\n",
      "26 22050\n",
      "25 22050\n",
      "27 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "26 22050\n",
      "26 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "26 "
     ]
    }
   ],
   "source": [
    "for key in keys_s:\n",
    "    sample, sr = librosa.load(f'../Dataset-for-Binary/base-audio/audio_{key}.wav')\n",
    "    print(sr)\n",
    "    print(len(isolator(sample, sr, 1024, 225, 2400, 12000, 0.06)), end=' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dd6f724446d4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.171485Z",
     "start_time": "2024-08-21T17:56:58.567245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File audio_1.wav length: 25\n",
      "File audio_2.wav length: 25\n",
      "File audio_3.wav length: 25\n",
      "File audio_4.wav length: 25\n",
      "File audio_5.wav length: 25\n",
      "File audio_6.wav length: 26\n",
      "File audio_7.wav length: 25\n",
      "File audio_8.wav length: 25\n",
      "File audio_9.wav length: 27\n",
      "File audio_0.wav length: 26\n",
      "File audio_Q.wav length: 27\n",
      "File audio_W.wav length: 28\n",
      "File audio_E.wav length: 28\n",
      "File audio_R.wav length: 25\n",
      "File audio_T.wav length: 26\n",
      "File audio_Y.wav length: 25\n",
      "File audio_U.wav length: 25\n",
      "File audio_I.wav length: 25\n",
      "File audio_O.wav length: 25\n",
      "File audio_P.wav length: 25\n",
      "File audio_A.wav length: 25\n",
      "File audio_S.wav length: 25\n",
      "File audio_D.wav length: 25\n",
      "File audio_F.wav length: 27\n",
      "File audio_G.wav length: 26\n",
      "File audio_H.wav length: 25\n",
      "File audio_J.wav length: 27\n",
      "File audio_K.wav length: 25\n",
      "File audio_L.wav length: 25\n",
      "File audio_Z.wav length: 25\n",
      "File audio_X.wav length: 26\n",
      "File audio_C.wav length: 26\n",
      "File audio_V.wav length: 25\n",
      "File audio_B.wav length: 25\n",
      "File audio_N.wav length: 25\n",
      "File audio_M.wav length: 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.00017975706, -0.00012727422, -9.371064e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.000497586, 0.00049031794, 0.0005512878, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0003178973, 0.00034715672, 0.0003719765, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.00268178, 0.0026667328, 0.0026979204, 0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0064755157, 0.0063309446, 0.0053669587, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>35</td>\n",
       "      <td>[-0.250816, -0.25290224, -0.25483984, -0.25665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.13746458, 0.13331985, 0.12892573, 0.1242144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.0017171801, 0.0016756053, 0.0016776036, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>35</td>\n",
       "      <td>[-0.00014814909, -0.00018149172, -0.0002237720...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.00025164883, 0.00018340972, 0.00015876113, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Key                                               File\n",
       "0      0  [-0.00017975706, -0.00012727422, -9.371064e-05...\n",
       "1      0  [0.000497586, 0.00049031794, 0.0005512878, 0.0...\n",
       "2      0  [0.0003178973, 0.00034715672, 0.0003719765, 0....\n",
       "3      0  [0.00268178, 0.0026667328, 0.0026979204, 0.002...\n",
       "4      0  [0.0064755157, 0.0063309446, 0.0053669587, 0.0...\n",
       "..   ...                                                ...\n",
       "916   35  [-0.250816, -0.25290224, -0.25483984, -0.25665...\n",
       "917   35  [0.13746458, 0.13331985, 0.12892573, 0.1242144...\n",
       "918   35  [0.0017171801, 0.0016756053, 0.0016776036, 0.0...\n",
       "919   35  [-0.00014814909, -0.00018149172, -0.0002237720...\n",
       "920   35  [0.00025164883, 0.00018340972, 0.00015876113, ...\n",
       "\n",
       "[921 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_fft = 1024\n",
    "hop_length = 225\n",
    "before = 2400\n",
    "after = 12000\n",
    "mbp_dataset = create_dataset(n_fft, hop_length, before, after)\n",
    "mbp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89e46a8b42021c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.210310Z",
     "start_time": "2024-08-21T17:56:59.172105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,)\n",
      "(20, 29)\n"
     ]
    }
   ],
   "source": [
    "audio_samples = mbp_dataset['File'].values.tolist()\n",
    "labels = mbp_dataset['Key'].values.tolist()\n",
    "\n",
    "audioDataset = np.array(audio_samples, dtype = object)\n",
    "print(audio_samples[0].shape)\n",
    "mfcc = librosa.feature.mfcc(y=audio_samples[0], sr=44100) # shape: (n_mfcc, t)\n",
    "print(mfcc.shape)\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d2cd83eaab0466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.244806Z",
     "start_time": "2024-08-21T17:56:59.217910Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "#       samples_shape = samples.shape\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4) #Max shift (0.4)\n",
    "        random_shift = random.randint(0, shift) #Random number between 0 and 0.4*len(samples)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3598b8c7bcd285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.286280Z",
     "start_time": "2024-08-21T17:56:59.250402Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_shift(samples):\n",
    "    samples = samples.flatten()\n",
    "    shift = int(len(samples) * 0.4) #Max shift (0.4)\n",
    "    random_shift = random.randint(0, shift) #Random number between 0 and 0.4*len(samples)\n",
    "    data_roll = np.roll(samples, random_shift)\n",
    "    return data_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a429af86b3206df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.345608Z",
     "start_time": "2024-08-21T17:56:59.308102Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=samples, sr=44100, n_mels=64, n_fft=1024, hop_length=225)\n",
    "        mel_spec_resized = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "        mel_spec_resized = np.expand_dims(mel_spec_resized, axis=0)\n",
    "        return torch.tensor(mel_spec_resized)\n",
    "\n",
    "\n",
    "class ToMelSpectrogramMfcc:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=samples, sr=44100, n_mels=64, n_fft=n_fft, hop_length=hop_length)\n",
    "        mel_spec = librosa.feature.mfcc(S=librosa.power_to_db(mel_spec))\n",
    "        mel_spec_resized = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "        mel_spec_resized = np.expand_dims(mel_spec_resized, axis=0)\n",
    "\n",
    "        return torch.tensor(mel_spec_resized)\n",
    "\n",
    "\n",
    "class ToMfcc:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "        \n",
    "        mfcc_spec = librosa.feature.mfcc(y=samples, sr=44100)\n",
    "        mfcc_spec = np.transpose(mfcc_spec)\n",
    "        return torch.tensor(mfcc_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f019fc2bc0e25204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.347730Z",
     "start_time": "2024-08-21T17:56:59.346203Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = Compose([ToMelSpectrogram()])\n",
    "transform_mfcc = Compose([ToMfcc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b3b3ca9f37f4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:01.583816Z",
     "start_time": "2024-08-21T17:57:01.569876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842\n",
      "1842\n"
     ]
    }
   ],
   "source": [
    "audio_samples_new = audio_samples.copy() # audio samples CNN\n",
    "\n",
    "for i, sample in enumerate(audio_samples):\n",
    "    audio_samples_new.append(time_shift(sample))\n",
    "    labels.append(labels[i])\n",
    "    \n",
    "# convert labels to a numpy array\n",
    "labels = np.array(labels)\n",
    "print(len(audio_samples_new))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9e929216f37f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.494105Z",
     "start_time": "2024-08-21T17:57:01.586778Z"
    }
   },
   "outputs": [],
   "source": [
    "audioDatasetFin, audioDatasetMfcc = [], []\n",
    "\n",
    "for i in range(len(audio_samples_new)):\n",
    "    transformed_sample = transform(audio_samples_new[i])\n",
    "    transformed_mfcc = transform_mfcc(audio_samples_new[i])\n",
    "    audioDatasetFin.append((transformed_sample, labels[i]))\n",
    "    audioDatasetMfcc.append((transformed_sample, transformed_mfcc, labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d1788d46fe597f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.510318Z",
     "start_time": "2024-08-21T17:57:09.496003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioDatasetFin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf735153a104afec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.545687Z",
     "start_time": "2024-08-21T17:57:09.516010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioDatasetMfcc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c53f1c392a2eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.562851Z",
     "start_time": "2024-08-21T17:57:09.555932Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MfccLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2, num_classes=36):\n",
    "        super(MfccLSTM, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.LazyLinear(64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "    \n",
    "        self.fc3 = nn.LazyLinear(128)\n",
    "        self.final_lstm = nn.LSTM(1, 64, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.LazyLinear(num_classes)\n",
    "    \n",
    "    def forward(self, image_input, sequence_input):\n",
    "        # must return shape (batch_size, num_classes) \n",
    "        # batch_size: right now is 16\n",
    "        # num_classes: right now is 36\n",
    "        x1 = self.conv(image_input)\n",
    "        out1, _ = self.lstm(sequence_input)\n",
    "        out1_dp = self.dropout(out1)\n",
    "        # print(f'output of first lstm: {out1_dp.shape[1:]}')\n",
    "        out2, _ = self.lstm2(out1_dp[:, -1, :])\n",
    "        out2_dp = self.dropout(out2)\n",
    "        # print(f'output of second lstm: {out2_dp.shape[1:]}')\n",
    "        x2 = self.fc2(self.fc1(out2_dp))\n",
    "        x3 = torch.cat((x1, x2), 1)\n",
    "        # print(f'output of concatenation: {x3.shape[1:]}')\n",
    "        # x = self.fc(final_out[:, -1, :])\n",
    "        x = self.fc(x3)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "876758bd07bc26b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.568636Z",
     "start_time": "2024-08-21T17:57:09.564462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=36):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.LazyLinear(512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e1ab811f0d1abfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:03.746585Z",
     "start_time": "2024-08-21T21:43:03.734939Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_with_cross_validation(dataset, num_epochs, model_name, patience=15, random_state=42, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f'Fold {fold+1}/{n_splits}')\n",
    "        \n",
    "        # Split the dataset into training and validation sets\n",
    "        train_set = Subset(dataset, train_idx)\n",
    "        val_set = Subset(dataset, val_idx)\n",
    "        train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=16, shuffle=True)\n",
    "        \n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = MfccLSTM(input_size=20, hidden_size=32, num_classes=36, output_size=64)\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        best_val_acc, epochs_no_imp = 0, 0\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            tic = time.perf_counter()\n",
    "            \n",
    "            for images, sequences, labels in train_loader:\n",
    "                images = images.to(device)\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #converting labels to Long to avoid error \"not implemented for Int\"\n",
    "                labels = labels.long()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images, sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted_train = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted_train == labels).sum().item()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            toc = time.perf_counter()\n",
    "            time_taken = toc - tic\n",
    "            \n",
    "            epoch_train_loss /= len(train_loader.dataset)\n",
    "            train_accuracy = correct_train / total_train\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            # Evaluation of the model\n",
    "            model.eval()\n",
    "            total, correct = 0, 0\n",
    "            for images, sequences, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images, sequences)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_accuracy = correct / total\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Iter Time: {time_taken:.2f}s\")\n",
    "                \n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                epochs_no_imp = 0\n",
    "                best_model_state = model.state_dict()  # Save the best model\n",
    "            else:\n",
    "                epochs_no_imp += 1\n",
    "            if epochs_no_imp >= patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                model.load_state_dict(best_model_state)  # Load the best model\n",
    "                break\n",
    "        \n",
    "        fold_results.append((epoch+1, best_val_acc))\n",
    "        print(f'Fold {fold+1} Best Validation Accuracy: {best_val_acc:.4f}')\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e58aef22cf15f974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:05.428428Z",
     "start_time": "2024-08-21T21:43:05.425143Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_mfcc(dataset, model_path, device_external):\n",
    "    images_test_set = [t[0] for t in dataset]\n",
    "    sequences_test_set = [t[1] for t in dataset]\n",
    "    \n",
    "    images = torch.stack(images_test_set)\n",
    "    sequences = torch.stack(sequences_test_set)\n",
    "    device = torch.device(device_external) #default to mps\n",
    "    images = images.to(device)\n",
    "    sequences = sequences.to(device)\n",
    "    model = MfccLSTM(input_size=20, hidden_size=32, num_classes=36, output_size=64)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images, sequences)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    pred = []\n",
    "    keyss = '1234567890QWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "    phrase = predicted.tolist()\n",
    "    for i in range(len(phrase)):\n",
    "        pred.append(keyss[phrase[i]])\n",
    "\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dea4576ee7857b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:06.012807Z",
     "start_time": "2024-08-21T21:43:06.010208Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_csv(model_name, num_epochs, description, accuracy, precision, recall, f1_score):\n",
    "    csv_file_path = 'model_comparison.csv'\n",
    "    \n",
    "    # Read the existing CSV file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, create an empty DataFrame with the correct columns\n",
    "        df = pd.DataFrame(columns=['Datetime', 'Name', 'Epochs', 'Description', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "        \n",
    "    # Data to append\n",
    "    current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Remove newline characters from the description\n",
    "    description = description.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # Create a new column with the relevant information\n",
    "    new_data = {\n",
    "        'Datetime': [current_datetime],\n",
    "        'Name': [model_name],\n",
    "        'Epochs': [num_epochs],\n",
    "        'Description': [description],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1': [f1_score],\n",
    "    }\n",
    "    \n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7407a641de41b299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:44:33.450713Z",
     "start_time": "2024-08-21T21:43:10.233998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "Epoch [5/100], Train Loss: 1.9547, Train Accuracy: 0.3766, Val Accuracy: 0.3986, Iter Time: 0.76s\n",
      "Epoch [10/100], Train Loss: 1.0429, Train Accuracy: 0.6604, Val Accuracy: 0.4392, Iter Time: 0.74s\n",
      "Epoch [15/100], Train Loss: 0.6274, Train Accuracy: 0.7970, Val Accuracy: 0.6014, Iter Time: 0.74s\n",
      "Epoch [20/100], Train Loss: 0.3447, Train Accuracy: 0.8906, Val Accuracy: 0.5676, Iter Time: 0.77s\n",
      "Epoch [25/100], Train Loss: 0.3127, Train Accuracy: 0.9087, Val Accuracy: 0.6081, Iter Time: 0.76s\n",
      "Epoch [30/100], Train Loss: 0.1851, Train Accuracy: 0.9525, Val Accuracy: 0.6486, Iter Time: 0.76s\n",
      "Epoch [35/100], Train Loss: 0.1760, Train Accuracy: 0.9585, Val Accuracy: 0.6284, Iter Time: 0.72s\n",
      "Epoch [40/100], Train Loss: 0.1035, Train Accuracy: 0.9721, Val Accuracy: 0.6284, Iter Time: 0.73s\n",
      "Epoch [45/100], Train Loss: 0.0605, Train Accuracy: 0.9857, Val Accuracy: 0.6622, Iter Time: 0.73s\n",
      "Epoch [50/100], Train Loss: 0.0446, Train Accuracy: 0.9887, Val Accuracy: 0.6892, Iter Time: 0.76s\n",
      "Epoch [55/100], Train Loss: 0.4021, Train Accuracy: 0.8853, Val Accuracy: 0.6419, Iter Time: 0.74s\n",
      "Epoch [60/100], Train Loss: 0.0511, Train Accuracy: 0.9811, Val Accuracy: 0.6554, Iter Time: 0.78s\n",
      "Epoch [65/100], Train Loss: 0.0310, Train Accuracy: 0.9917, Val Accuracy: 0.6689, Iter Time: 0.77s\n",
      "Early stopping after 65 epochs\n",
      "Fold 1 Best Validation Accuracy: 0.6892\n",
      "Fold 2/10\n",
      "Epoch [5/100], Train Loss: 1.8350, Train Accuracy: 0.4445, Val Accuracy: 0.3176, Iter Time: 0.78s\n",
      "Epoch [10/100], Train Loss: 0.8545, Train Accuracy: 0.7230, Val Accuracy: 0.6419, Iter Time: 0.77s\n",
      "Epoch [15/100], Train Loss: 0.5541, Train Accuracy: 0.8257, Val Accuracy: 0.6622, Iter Time: 0.81s\n",
      "Epoch [20/100], Train Loss: 0.3756, Train Accuracy: 0.8800, Val Accuracy: 0.6689, Iter Time: 0.88s\n",
      "Epoch [25/100], Train Loss: 0.2375, Train Accuracy: 0.9238, Val Accuracy: 0.7095, Iter Time: 0.83s\n",
      "Epoch [30/100], Train Loss: 0.3766, Train Accuracy: 0.9026, Val Accuracy: 0.7297, Iter Time: 0.80s\n",
      "Epoch [35/100], Train Loss: 0.2219, Train Accuracy: 0.9328, Val Accuracy: 0.7095, Iter Time: 0.86s\n",
      "Epoch [40/100], Train Loss: 0.1804, Train Accuracy: 0.9472, Val Accuracy: 0.7095, Iter Time: 0.82s\n",
      "Epoch [45/100], Train Loss: 0.0790, Train Accuracy: 0.9796, Val Accuracy: 0.7500, Iter Time: 0.81s\n",
      "Early stopping after 47 epochs\n",
      "Fold 2 Best Validation Accuracy: 0.7770\n",
      "Fold 3/10\n",
      "Epoch [5/100], Train Loss: 1.7187, Train Accuracy: 0.4762, Val Accuracy: 0.3784, Iter Time: 0.79s\n",
      "Epoch [10/100], Train Loss: 0.9191, Train Accuracy: 0.7109, Val Accuracy: 0.4459, Iter Time: 0.83s\n",
      "Epoch [15/100], Train Loss: 0.5324, Train Accuracy: 0.8242, Val Accuracy: 0.5405, Iter Time: 0.85s\n",
      "Epoch [20/100], Train Loss: 0.4189, Train Accuracy: 0.8694, Val Accuracy: 0.5541, Iter Time: 0.84s\n",
      "Epoch [25/100], Train Loss: 0.2885, Train Accuracy: 0.9132, Val Accuracy: 0.5473, Iter Time: 0.85s\n",
      "Epoch [30/100], Train Loss: 0.1649, Train Accuracy: 0.9532, Val Accuracy: 0.5878, Iter Time: 0.94s\n",
      "Epoch [35/100], Train Loss: 0.2184, Train Accuracy: 0.9336, Val Accuracy: 0.5811, Iter Time: 0.93s\n",
      "Epoch [40/100], Train Loss: 0.2670, Train Accuracy: 0.9457, Val Accuracy: 0.6014, Iter Time: 0.93s\n",
      "Epoch [45/100], Train Loss: 0.1351, Train Accuracy: 0.9630, Val Accuracy: 0.5541, Iter Time: 0.85s\n",
      "Early stopping after 46 epochs\n",
      "Fold 3 Best Validation Accuracy: 0.6149\n",
      "Fold 4/10\n",
      "Epoch [5/100], Train Loss: 1.8612, Train Accuracy: 0.4201, Val Accuracy: 0.3537, Iter Time: 0.81s\n",
      "Epoch [10/100], Train Loss: 0.9720, Train Accuracy: 0.7029, Val Accuracy: 0.5102, Iter Time: 0.84s\n",
      "Epoch [15/100], Train Loss: 0.5253, Train Accuracy: 0.8363, Val Accuracy: 0.5986, Iter Time: 0.84s\n",
      "Epoch [20/100], Train Loss: 0.3396, Train Accuracy: 0.8974, Val Accuracy: 0.6327, Iter Time: 0.94s\n",
      "Epoch [25/100], Train Loss: 0.2203, Train Accuracy: 0.9367, Val Accuracy: 0.6939, Iter Time: 0.80s\n",
      "Epoch [30/100], Train Loss: 0.2218, Train Accuracy: 0.9351, Val Accuracy: 0.7075, Iter Time: 0.80s\n",
      "Epoch [35/100], Train Loss: 0.2195, Train Accuracy: 0.9321, Val Accuracy: 0.6531, Iter Time: 0.79s\n",
      "Epoch [40/100], Train Loss: 0.1952, Train Accuracy: 0.9487, Val Accuracy: 0.6871, Iter Time: 0.79s\n",
      "Epoch [45/100], Train Loss: 0.0798, Train Accuracy: 0.9811, Val Accuracy: 0.7007, Iter Time: 0.88s\n",
      "Epoch [50/100], Train Loss: 0.4524, Train Accuracy: 0.8846, Val Accuracy: 0.6395, Iter Time: 0.89s\n",
      "Epoch [55/100], Train Loss: 0.0461, Train Accuracy: 0.9879, Val Accuracy: 0.7415, Iter Time: 0.95s\n",
      "Epoch [60/100], Train Loss: 0.1271, Train Accuracy: 0.9713, Val Accuracy: 0.7007, Iter Time: 0.78s\n",
      "Epoch [65/100], Train Loss: 0.0551, Train Accuracy: 0.9872, Val Accuracy: 0.7483, Iter Time: 0.78s\n",
      "Epoch [70/100], Train Loss: 0.0440, Train Accuracy: 0.9879, Val Accuracy: 0.6939, Iter Time: 0.77s\n",
      "Epoch [75/100], Train Loss: 0.0483, Train Accuracy: 0.9842, Val Accuracy: 0.6939, Iter Time: 0.76s\n",
      "Epoch [80/100], Train Loss: 0.1364, Train Accuracy: 0.9630, Val Accuracy: 0.6667, Iter Time: 0.76s\n",
      "Early stopping after 80 epochs\n",
      "Fold 4 Best Validation Accuracy: 0.7483\n",
      "Fold 5/10\n",
      "Epoch [5/100], Train Loss: 1.8272, Train Accuracy: 0.4268, Val Accuracy: 0.3673, Iter Time: 0.76s\n",
      "Epoch [10/100], Train Loss: 0.9510, Train Accuracy: 0.6983, Val Accuracy: 0.5238, Iter Time: 0.76s\n",
      "Epoch [15/100], Train Loss: 0.5648, Train Accuracy: 0.8160, Val Accuracy: 0.5850, Iter Time: 0.77s\n",
      "Epoch [20/100], Train Loss: 0.3618, Train Accuracy: 0.8824, Val Accuracy: 0.5850, Iter Time: 0.75s\n",
      "Epoch [25/100], Train Loss: 0.2395, Train Accuracy: 0.9329, Val Accuracy: 0.5782, Iter Time: 0.77s\n",
      "Epoch [30/100], Train Loss: 0.1863, Train Accuracy: 0.9359, Val Accuracy: 0.6259, Iter Time: 0.76s\n",
      "Epoch [35/100], Train Loss: 0.1074, Train Accuracy: 0.9706, Val Accuracy: 0.6735, Iter Time: 0.76s\n",
      "Epoch [40/100], Train Loss: 0.0735, Train Accuracy: 0.9834, Val Accuracy: 0.6939, Iter Time: 0.77s\n",
      "Epoch [45/100], Train Loss: 0.4259, Train Accuracy: 0.8989, Val Accuracy: 0.6395, Iter Time: 0.77s\n",
      "Epoch [50/100], Train Loss: 0.1146, Train Accuracy: 0.9789, Val Accuracy: 0.6122, Iter Time: 0.75s\n",
      "Epoch [55/100], Train Loss: 0.0361, Train Accuracy: 0.9910, Val Accuracy: 0.6735, Iter Time: 0.78s\n",
      "Early stopping after 55 epochs\n",
      "Fold 5 Best Validation Accuracy: 0.6939\n",
      "Fold 6/10\n",
      "Epoch [5/100], Train Loss: 1.7581, Train Accuracy: 0.4517, Val Accuracy: 0.2925, Iter Time: 0.76s\n",
      "Epoch [10/100], Train Loss: 0.9999, Train Accuracy: 0.6750, Val Accuracy: 0.4286, Iter Time: 0.76s\n",
      "Epoch [15/100], Train Loss: 0.6215, Train Accuracy: 0.8137, Val Accuracy: 0.4490, Iter Time: 0.75s\n",
      "Epoch [20/100], Train Loss: 0.4483, Train Accuracy: 0.8537, Val Accuracy: 0.5170, Iter Time: 0.77s\n",
      "Epoch [25/100], Train Loss: 0.2822, Train Accuracy: 0.9095, Val Accuracy: 0.5374, Iter Time: 0.76s\n",
      "Epoch [30/100], Train Loss: 0.2035, Train Accuracy: 0.9351, Val Accuracy: 0.5986, Iter Time: 0.76s\n",
      "Epoch [35/100], Train Loss: 0.2349, Train Accuracy: 0.9284, Val Accuracy: 0.5646, Iter Time: 0.79s\n",
      "Epoch [40/100], Train Loss: 0.1092, Train Accuracy: 0.9661, Val Accuracy: 0.5986, Iter Time: 0.77s\n",
      "Epoch [45/100], Train Loss: 0.0616, Train Accuracy: 0.9864, Val Accuracy: 0.5986, Iter Time: 0.77s\n",
      "Epoch [50/100], Train Loss: 0.1635, Train Accuracy: 0.9532, Val Accuracy: 0.5646, Iter Time: 0.77s\n",
      "Early stopping after 54 epochs\n",
      "Fold 6 Best Validation Accuracy: 0.6531\n",
      "Fold 7/10\n",
      "Epoch [5/100], Train Loss: 1.9097, Train Accuracy: 0.3854, Val Accuracy: 0.3810, Iter Time: 0.78s\n",
      "Epoch [10/100], Train Loss: 0.9843, Train Accuracy: 0.6772, Val Accuracy: 0.5170, Iter Time: 0.78s\n",
      "Epoch [15/100], Train Loss: 0.5808, Train Accuracy: 0.8047, Val Accuracy: 0.6735, Iter Time: 0.77s\n",
      "Epoch [20/100], Train Loss: 0.3599, Train Accuracy: 0.8944, Val Accuracy: 0.6871, Iter Time: 0.78s\n",
      "Epoch [25/100], Train Loss: 0.2803, Train Accuracy: 0.9095, Val Accuracy: 0.6667, Iter Time: 0.75s\n",
      "Epoch [30/100], Train Loss: 0.1885, Train Accuracy: 0.9465, Val Accuracy: 0.6803, Iter Time: 0.77s\n",
      "Epoch [35/100], Train Loss: 0.1330, Train Accuracy: 0.9615, Val Accuracy: 0.6939, Iter Time: 0.76s\n",
      "Epoch [40/100], Train Loss: 0.2278, Train Accuracy: 0.9321, Val Accuracy: 0.7007, Iter Time: 0.76s\n",
      "Epoch [45/100], Train Loss: 0.0996, Train Accuracy: 0.9819, Val Accuracy: 0.6735, Iter Time: 0.76s\n",
      "Epoch [50/100], Train Loss: 0.0459, Train Accuracy: 0.9894, Val Accuracy: 0.7279, Iter Time: 0.77s\n",
      "Epoch [55/100], Train Loss: 0.0354, Train Accuracy: 0.9902, Val Accuracy: 0.7483, Iter Time: 0.77s\n",
      "Epoch [60/100], Train Loss: 0.1139, Train Accuracy: 0.9706, Val Accuracy: 0.7075, Iter Time: 0.78s\n",
      "Epoch [65/100], Train Loss: 0.0520, Train Accuracy: 0.9827, Val Accuracy: 0.7143, Iter Time: 0.77s\n",
      "Epoch [70/100], Train Loss: 0.0328, Train Accuracy: 0.9910, Val Accuracy: 0.7211, Iter Time: 0.77s\n",
      "Early stopping after 70 epochs\n",
      "Fold 7 Best Validation Accuracy: 0.7483\n",
      "Fold 8/10\n",
      "Epoch [5/100], Train Loss: 1.7928, Train Accuracy: 0.4419, Val Accuracy: 0.3333, Iter Time: 0.76s\n",
      "Epoch [10/100], Train Loss: 0.8188, Train Accuracy: 0.7293, Val Accuracy: 0.5102, Iter Time: 0.77s\n",
      "Epoch [15/100], Train Loss: 0.4389, Train Accuracy: 0.8620, Val Accuracy: 0.6395, Iter Time: 0.77s\n",
      "Epoch [20/100], Train Loss: 0.3092, Train Accuracy: 0.9035, Val Accuracy: 0.5510, Iter Time: 0.76s\n",
      "Epoch [25/100], Train Loss: 0.2449, Train Accuracy: 0.9178, Val Accuracy: 0.6054, Iter Time: 0.77s\n",
      "Epoch [30/100], Train Loss: 0.1699, Train Accuracy: 0.9630, Val Accuracy: 0.6667, Iter Time: 0.77s\n",
      "Epoch [35/100], Train Loss: 0.1435, Train Accuracy: 0.9570, Val Accuracy: 0.6531, Iter Time: 0.75s\n",
      "Epoch [40/100], Train Loss: 0.1412, Train Accuracy: 0.9608, Val Accuracy: 0.6599, Iter Time: 0.76s\n",
      "Early stopping after 42 epochs\n",
      "Fold 8 Best Validation Accuracy: 0.6939\n",
      "Fold 9/10\n",
      "Epoch [5/100], Train Loss: 1.7937, Train Accuracy: 0.4548, Val Accuracy: 0.3946, Iter Time: 0.76s\n",
      "Epoch [10/100], Train Loss: 0.8605, Train Accuracy: 0.7360, Val Accuracy: 0.5374, Iter Time: 0.86s\n",
      "Epoch [15/100], Train Loss: 0.5146, Train Accuracy: 0.8348, Val Accuracy: 0.6122, Iter Time: 0.78s\n",
      "Epoch [20/100], Train Loss: 0.4006, Train Accuracy: 0.8846, Val Accuracy: 0.6667, Iter Time: 0.79s\n",
      "Epoch [25/100], Train Loss: 0.3299, Train Accuracy: 0.8929, Val Accuracy: 0.6259, Iter Time: 0.82s\n",
      "Epoch [30/100], Train Loss: 0.2000, Train Accuracy: 0.9502, Val Accuracy: 0.6531, Iter Time: 0.82s\n",
      "Epoch [35/100], Train Loss: 0.1448, Train Accuracy: 0.9525, Val Accuracy: 0.6531, Iter Time: 0.95s\n",
      "Epoch [40/100], Train Loss: 0.1267, Train Accuracy: 0.9646, Val Accuracy: 0.7279, Iter Time: 0.81s\n",
      "Epoch [45/100], Train Loss: 0.1287, Train Accuracy: 0.9676, Val Accuracy: 0.6599, Iter Time: 1.02s\n",
      "Epoch [50/100], Train Loss: 0.1384, Train Accuracy: 0.9774, Val Accuracy: 0.7007, Iter Time: 0.94s\n",
      "Epoch [55/100], Train Loss: 0.0449, Train Accuracy: 0.9872, Val Accuracy: 0.7075, Iter Time: 0.93s\n",
      "Early stopping after 55 epochs\n",
      "Fold 9 Best Validation Accuracy: 0.7279\n",
      "Fold 10/10\n",
      "Epoch [5/100], Train Loss: 1.7992, Train Accuracy: 0.4434, Val Accuracy: 0.3333, Iter Time: 0.93s\n",
      "Epoch [10/100], Train Loss: 0.9487, Train Accuracy: 0.6878, Val Accuracy: 0.5170, Iter Time: 0.91s\n",
      "Epoch [15/100], Train Loss: 0.5320, Train Accuracy: 0.8333, Val Accuracy: 0.5238, Iter Time: 1.03s\n",
      "Epoch [20/100], Train Loss: 0.4002, Train Accuracy: 0.8771, Val Accuracy: 0.5306, Iter Time: 0.88s\n",
      "Epoch [25/100], Train Loss: 0.2643, Train Accuracy: 0.9186, Val Accuracy: 0.5986, Iter Time: 0.83s\n",
      "Epoch [30/100], Train Loss: 0.1794, Train Accuracy: 0.9427, Val Accuracy: 0.6122, Iter Time: 0.85s\n",
      "Epoch [35/100], Train Loss: 0.2205, Train Accuracy: 0.9412, Val Accuracy: 0.6122, Iter Time: 0.84s\n",
      "Epoch [40/100], Train Loss: 0.1636, Train Accuracy: 0.9563, Val Accuracy: 0.6327, Iter Time: 0.83s\n",
      "Early stopping after 42 epochs\n",
      "Fold 10 Best Validation Accuracy: 0.6395\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PyTorch is not linked with support for mps devices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         real_num_epochs \u001b[38;5;241m=\u001b[39m fold_stat[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Prediction part\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m labels_set \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m test_set]\n\u001b[0;32m     24\u001b[0m final_labels_set \u001b[38;5;241m=\u001b[39m [keys_s[ind] \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m labels_set]\n",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m, in \u001b[0;36mpredict_mfcc\u001b[1;34m(dataset, model_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(sequences_test_set)\n\u001b[0;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m MfccLSTM(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m36\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PyTorch is not linked with support for mps devices"
     ]
    }
   ],
   "source": [
    "# current random state to split the dataset\n",
    "random_state = 42\n",
    "\n",
    "# values for current run\n",
    "train_final_set, test_set = train_test_split(audioDatasetMfcc, test_size=0.2, random_state=random_state)\n",
    "num_epochs = 100\n",
    "main_architecture = \"CNN_LSTM\"\n",
    "currday = datetime.today().strftime('%Y-%m-%d')\n",
    "model_name = f\"model_multiclass_{num_epochs}_{main_architecture}_{currday}.pth\"\n",
    "description = \"2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \\n 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes\"\n",
    "\n",
    "# Training part\n",
    "fold_stats = train_with_cross_validation(train_final_set, num_epochs, model_name, random_state=random_state)\n",
    "max_val = 0\n",
    "real_num_epochs = 0\n",
    "for fold_stat in fold_stats: #using folds instead of LOO\n",
    "    if fold_stat[1] > max_val:\n",
    "        max_val = fold_stat[1]\n",
    "        real_num_epochs = fold_stat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "680fb321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results!\n",
      "Model: model_multiclass_100_CNN_LSTM_2024-08-22.pth\n",
      "2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \n",
      " 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes\n",
      "Epochs: 47\n",
      "Accuracy: 0.6341463414634146\n",
      "Precision: 0.6488551186467852\n",
      "Recall: 0.6611112267362267\n",
      "F1 Score: 0.6378695667148576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kat\\.conda\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# Prediction part\n",
    "prediction = predict_mfcc(test_set, model_name, device)\n",
    "labels_set = [t[2] for t in test_set]\n",
    "final_labels_set = [keys_s[ind] for ind in labels_set]\n",
    "\n",
    "# Metrics calculation\n",
    "accuracy = accuracy_score(final_labels_set, prediction[0])\n",
    "precision = precision_score(final_labels_set, prediction[0], average='macro')\n",
    "recall = recall_score(final_labels_set, prediction[0], average='macro')\n",
    "f1 = sklearn.metrics.f1_score(final_labels_set, prediction[0], average='macro')\n",
    "\n",
    "# Save in csv file\n",
    "save_csv(model_name, real_num_epochs, description, accuracy, precision, recall, f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Final Results!\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(description)\n",
    "print(f\"Epochs: {real_num_epochs}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cda12c04ba1a39d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:46:13.060776Z",
     "start_time": "2024-08-21T21:46:13.057310Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def empty_file(csv_file_path):\n",
    "    # Read the header (first row) of the CSV file\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Read the first row (header)\n",
    "    \n",
    "    # Write only the header back to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)  # Wr`ite the header back to the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa7e7268b306a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:46:13.698178Z",
     "start_time": "2024-08-21T21:46:13.695766Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty_file('model_comparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
