{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a122adee9a39c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.757210Z",
     "start_time": "2024-08-21T17:56:54.457070Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e579266",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9ad2373f64ed7deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.764952Z",
     "start_time": "2024-08-21T17:56:56.763360Z"
    }
   },
   "outputs": [],
   "source": [
    "# waveform function for me to not bang my keyboard\n",
    "def disp_waveform(signal, sr=None, color='blue'):\n",
    "    plt.figure(figsize=(7,2))\n",
    "    return librosa.display.waveshow(signal, sr=sr, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.767755Z",
     "start_time": "2024-08-21T17:56:56.765455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, n_fft, hop_length, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        disp_waveform(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        disp_waveform(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        disp_waveform(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*hop_length) + n_fft//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            # strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            # keystroke = transform(keystroke)\n",
    "            strokes.append(keystroke)\n",
    "            if show:\n",
    "                disp_waveform(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3c33893a14fb819c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.814715Z",
     "start_time": "2024-08-21T17:56:56.768186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants we actually need for the task\n",
    "#MBP_AUDIO_DIR = '../Dataset-for-Binary/base-audio/'\n",
    "MBP_AUDIO_DIR = '../Dataset-custom-audio/base-audio/' #for custom audio\n",
    "#keys_s = '1234567890QWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "keys_s = '1234567890' #for custom audio\n",
    "labels = list(keys_s)\n",
    "#keys = ['audio_' + k + '.wav' for k in labels]\n",
    "keys = [ k + '.wav' for k in labels] #for custom audio\n",
    "data_dict = {'Key':[], 'File':[]}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "2fee322473e2bfe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.817344Z",
     "start_time": "2024-08-21T17:56:56.815269Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_fft, hop_length, before, after, keys, custom_audio=False):\n",
    "    for i, File in enumerate(keys):\n",
    "        loc = MBP_AUDIO_DIR + File\n",
    "        samples, sr = librosa.load(loc)\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        strokes = isolator(samples, sr, n_fft, hop_length, before, after, prom, False )\n",
    "        print(f'File {File} length: {len(strokes)}')\n",
    "        label = [labels[i]]*len(strokes)\n",
    "        #works fine here\n",
    "        data_dict['Key'] += label\n",
    "        data_dict['File'] += strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if not l in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "        print(mapper)\n",
    "    df.replace({'Key': mapper}, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "953e2f0556453dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:58.565620Z",
     "start_time": "2024-08-21T17:56:56.817785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n",
      "61 22050\n",
      "60 22050\n",
      "56 22050\n",
      "59 22050\n",
      "60 22050\n",
      "55 22050\n",
      "60 22050\n",
      "59 22050\n",
      "58 22050\n",
      "59 "
     ]
    }
   ],
   "source": [
    "for key in keys_s:\n",
    "    #sample, sr = librosa.load(f'../Dataset-for-Binary/base-audio/audio_{key}.wav')\n",
    "    sample, sr = librosa.load(f'../Dataset-custom-audio/base-audio/{key}.wav') #for custom audio\n",
    "    print(sr)\n",
    "    print(len(isolator(sample, sr, 1024, 225, 2400, 12000, 0.06)), end=' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f2dd6f724446d4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.171485Z",
     "start_time": "2024-08-21T17:56:58.567245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1.wav length: 43\n",
      "File 2.wav length: 40\n",
      "File 3.wav length: 39\n",
      "File 4.wav length: 40\n",
      "File 5.wav length: 40\n",
      "File 6.wav length: 39\n",
      "File 7.wav length: 41\n",
      "File 8.wav length: 40\n",
      "File 9.wav length: 40\n",
      "File 0.wav length: 38\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '0': 9}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-2.8917696e-06, -1.5902851e-05, -1.0187194e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0035704505, -0.0060559334, -0.0035010458, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0059701907, 0.006984167, 0.0058809407, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.007907201, 0.009311641, 0.009059044, 0.0084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.00831442, 0.0062111467, 0.0017823654, 1.734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.0076228883, 0.008890776, 0.009433404, 0.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>9</td>\n",
       "      <td>[-0.011311473, -0.009117752, -0.007440676, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.052618206, 0.054623783, 0.056411628, 0.0537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.000838196, 0.0022244581, 0.0025273692, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.019494854, 0.02011266, 0.021951836, 0.02182...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Key                                               File\n",
       "0      0  [-2.8917696e-06, -1.5902851e-05, -1.0187194e-0...\n",
       "1      0  [-0.0035704505, -0.0060559334, -0.0035010458, ...\n",
       "2      0  [0.0059701907, 0.006984167, 0.0058809407, 0.00...\n",
       "3      0  [0.007907201, 0.009311641, 0.009059044, 0.0084...\n",
       "4      0  [0.00831442, 0.0062111467, 0.0017823654, 1.734...\n",
       "..   ...                                                ...\n",
       "395    9  [0.0076228883, 0.008890776, 0.009433404, 0.007...\n",
       "396    9  [-0.011311473, -0.009117752, -0.007440676, -0....\n",
       "397    9  [0.052618206, 0.054623783, 0.056411628, 0.0537...\n",
       "398    9  [0.000838196, 0.0022244581, 0.0025273692, 0.00...\n",
       "399    9  [0.019494854, 0.02011266, 0.021951836, 0.02182...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working parameters for different audio sets\n",
    "# Dataset-for-Binary\n",
    "#n_fft = 1024 \n",
    "#hop_length = 225 \n",
    "#before = 2400 \n",
    "#after = 12000 \n",
    "# Normalized only audio\n",
    "#n_fft = 7 \n",
    "#hop_length = 4450 \n",
    "#before = 2400 \n",
    "#after = 12000 \n",
    "# Normalized and denoised audio\n",
    "n_fft = 9\n",
    "hop_length = 500\n",
    "before = 2400 \n",
    "after = 12000 \n",
    "mbp_dataset = create_dataset(n_fft, hop_length, before, after, keys)\n",
    "mbp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c89e46a8b42021c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.210310Z",
     "start_time": "2024-08-21T17:56:59.172105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,)\n",
      "(20, 29)\n"
     ]
    }
   ],
   "source": [
    "audio_samples = mbp_dataset['File'].values.tolist()\n",
    "labels = mbp_dataset['Key'].values.tolist()\n",
    "\n",
    "audioDataset = np.array(audio_samples, dtype = object)\n",
    "print(audio_samples[0].shape)\n",
    "mfcc = librosa.feature.mfcc(y=audio_samples[0], sr=44100) # shape: (n_mfcc, t)\n",
    "print(mfcc.shape)\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c940ac75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.8917696e-06, -1.5902851e-05, -1.0187194e-05, ...,\n",
       "       -3.5364130e-03, -2.8954418e-03,  3.6589988e-04], dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_samples[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "39d2cd83eaab0466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.244806Z",
     "start_time": "2024-08-21T17:56:59.217910Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "#       samples_shape = samples.shape\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4) #Max shift (0.4)\n",
    "        random_shift = random.randint(0, shift) #Random number between 0 and 0.4*len(samples)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ac3598b8c7bcd285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.286280Z",
     "start_time": "2024-08-21T17:56:59.250402Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_shift(samples):\n",
    "    samples = samples.flatten()\n",
    "    shift = int(len(samples) * 0.4) #Max shift (0.4)\n",
    "    random_shift = random.randint(0, shift) #Random number between 0 and 0.4*len(samples)\n",
    "    data_roll = np.roll(samples, random_shift)\n",
    "    return data_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4a429af86b3206df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.345608Z",
     "start_time": "2024-08-21T17:56:59.308102Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=samples, sr=44100, n_mels=64, n_fft=1024, hop_length=225)\n",
    "        mel_spec_resized = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "        mel_spec_resized = np.expand_dims(mel_spec_resized, axis=0)\n",
    "        return torch.tensor(mel_spec_resized)\n",
    "\n",
    "\n",
    "class ToMelSpectrogramMfcc:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=samples, sr=44100, n_mels=64, n_fft=n_fft, hop_length=hop_length)\n",
    "        mel_spec = librosa.feature.mfcc(S=librosa.power_to_db(mel_spec))\n",
    "        mel_spec_resized = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "        mel_spec_resized = np.expand_dims(mel_spec_resized, axis=0)\n",
    "\n",
    "        return torch.tensor(mel_spec_resized)\n",
    "\n",
    "\n",
    "class ToMfcc:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "        \n",
    "        mfcc_spec = librosa.feature.mfcc(y=samples, sr=44100)\n",
    "        mfcc_spec = np.transpose(mfcc_spec)\n",
    "        return torch.tensor(mfcc_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "f019fc2bc0e25204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.347730Z",
     "start_time": "2024-08-21T17:56:59.346203Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = Compose([ToMelSpectrogram()])\n",
    "transform_mfcc = Compose([ToMfcc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "44b3b3ca9f37f4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:01.583816Z",
     "start_time": "2024-08-21T17:57:01.569876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "audio_samples_new = audio_samples.copy() # audio samples CNN\n",
    "\n",
    "for i, sample in enumerate(audio_samples):\n",
    "    audio_samples_new.append(time_shift(sample))\n",
    "    labels.append(labels[i])\n",
    "    \n",
    "# convert labels to a numpy array\n",
    "labels = np.array(labels)\n",
    "print(len(audio_samples_new))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "be9e929216f37f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.494105Z",
     "start_time": "2024-08-21T17:57:01.586778Z"
    }
   },
   "outputs": [],
   "source": [
    "audioDatasetFin, audioDatasetMfcc = [], []\n",
    "\n",
    "for i in range(len(audio_samples_new)):\n",
    "    transformed_sample = transform(audio_samples_new[i])\n",
    "    transformed_mfcc = transform_mfcc(audio_samples_new[i])\n",
    "    audioDatasetFin.append((transformed_sample, labels[i]))\n",
    "    audioDatasetMfcc.append((transformed_sample, transformed_mfcc, labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "94d1788d46fe597f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.510318Z",
     "start_time": "2024-08-21T17:57:09.496003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioDatasetFin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "cf735153a104afec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.545687Z",
     "start_time": "2024-08-21T17:57:09.516010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioDatasetMfcc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "21c53f1c392a2eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.562851Z",
     "start_time": "2024-08-21T17:57:09.555932Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MfccLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2, num_classes=36):\n",
    "        super(MfccLSTM, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.LazyLinear(64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "    \n",
    "        self.fc3 = nn.LazyLinear(128)\n",
    "        self.final_lstm = nn.LSTM(1, 64, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.LazyLinear(num_classes)\n",
    "    \n",
    "    def forward(self, image_input, sequence_input):\n",
    "        # must return shape (batch_size, num_classes) \n",
    "        # batch_size: right now is 16\n",
    "        # num_classes: right now is 36\n",
    "        x1 = self.conv(image_input)\n",
    "        out1, _ = self.lstm(sequence_input)\n",
    "        out1_dp = self.dropout(out1)\n",
    "        # print(f'output of first lstm: {out1_dp.shape[1:]}')\n",
    "        out2, _ = self.lstm2(out1_dp[:, -1, :])\n",
    "        out2_dp = self.dropout(out2)\n",
    "        # print(f'output of second lstm: {out2_dp.shape[1:]}')\n",
    "        x2 = self.fc2(self.fc1(out2_dp))\n",
    "        x3 = torch.cat((x1, x2), 1)\n",
    "        # print(f'output of concatenation: {x3.shape[1:]}')\n",
    "        # x = self.fc(final_out[:, -1, :])\n",
    "        x = self.fc(x3)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "876758bd07bc26b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.568636Z",
     "start_time": "2024-08-21T17:57:09.564462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=36):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.LazyLinear(512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "9e1ab811f0d1abfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:03.746585Z",
     "start_time": "2024-08-21T21:43:03.734939Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_with_cross_validation(dataset, num_epochs, model_name, patience=15, random_state=42, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f'Fold {fold+1}/{n_splits}')\n",
    "        \n",
    "        # Split the dataset into training and validation sets\n",
    "        train_set = Subset(dataset, train_idx)\n",
    "        val_set = Subset(dataset, val_idx)\n",
    "        train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=16, shuffle=True)\n",
    "        \n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = MfccLSTM(input_size=20, hidden_size=32, num_classes=36, output_size=64)\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        best_val_acc, epochs_no_imp = 0, 0\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            tic = time.perf_counter()\n",
    "            \n",
    "            for images, sequences, labels in train_loader:\n",
    "                images = images.to(device)\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #converting labels to Long to avoid error \"not implemented for Int\"\n",
    "                labels = labels.long()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images, sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted_train = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted_train == labels).sum().item()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            toc = time.perf_counter()\n",
    "            time_taken = toc - tic\n",
    "            \n",
    "            epoch_train_loss /= len(train_loader.dataset)\n",
    "            train_accuracy = correct_train / total_train\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            # Evaluation of the model\n",
    "            model.eval()\n",
    "            total, correct = 0, 0\n",
    "            for images, sequences, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images, sequences)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_accuracy = correct / total\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Iter Time: {time_taken:.2f}s\")\n",
    "                \n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                epochs_no_imp = 0\n",
    "                best_model_state = model.state_dict()  # Save the best model\n",
    "            else:\n",
    "                epochs_no_imp += 1\n",
    "            if epochs_no_imp >= patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                model.load_state_dict(best_model_state)  # Load the best model\n",
    "                break\n",
    "        \n",
    "        fold_results.append((epoch+1, best_val_acc))\n",
    "        print(f'Fold {fold+1} Best Validation Accuracy: {best_val_acc:.4f}')\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "e58aef22cf15f974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:05.428428Z",
     "start_time": "2024-08-21T21:43:05.425143Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_mfcc(dataset, model_path, device_external, custom=False):\n",
    "    images_test_set = [t[0] for t in dataset]\n",
    "    sequences_test_set = [t[1] for t in dataset]\n",
    "    \n",
    "    images = torch.stack(images_test_set)\n",
    "    sequences = torch.stack(sequences_test_set)\n",
    "    device = torch.device(device_external) #default to mps\n",
    "    images = images.to(device)\n",
    "    sequences = sequences.to(device)\n",
    "    model = MfccLSTM(input_size=20, hidden_size=32, num_classes=36, output_size=64)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images, sequences)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    pred = []\n",
    "    keyss = '1234567890QWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "    if custom: #for using custom audio in project\n",
    "        keyss = '1234567890'\n",
    "    phrase = predicted.tolist()\n",
    "    for i in range(len(phrase)):\n",
    "        pred.append(keyss[phrase[i]])\n",
    "\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "dea4576ee7857b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:06.012807Z",
     "start_time": "2024-08-21T21:43:06.010208Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_csv(model_name, num_epochs, description, accuracy, precision, recall, f1_score):\n",
    "    csv_file_path = 'model_comparison.csv'\n",
    "    \n",
    "    # Read the existing CSV file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, create an empty DataFrame with the correct columns\n",
    "        df = pd.DataFrame(columns=['Datetime', 'Name', 'Epochs', 'Description', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "        \n",
    "    # Data to append\n",
    "    current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Remove newline characters from the description\n",
    "    description = description.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # Create a new column with the relevant information\n",
    "    new_data = {\n",
    "        'Datetime': [current_datetime],\n",
    "        'Name': [model_name],\n",
    "        'Epochs': [num_epochs],\n",
    "        'Description': [description],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1': [f1_score],\n",
    "    }\n",
    "    \n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21096271",
   "metadata": {},
   "source": [
    "# Running with audio from Dataset-for-Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "7407a641de41b299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:44:33.450713Z",
     "start_time": "2024-08-21T21:43:10.233998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kat\\.conda\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 1.2042, Train Accuracy: 0.5833, Val Accuracy: 0.4062, Iter Time: 0.40s\n",
      "Epoch [10/100], Train Loss: 0.5147, Train Accuracy: 0.8247, Val Accuracy: 0.6562, Iter Time: 0.40s\n",
      "Epoch [15/100], Train Loss: 0.2221, Train Accuracy: 0.9288, Val Accuracy: 0.6562, Iter Time: 0.42s\n",
      "Epoch [20/100], Train Loss: 0.1201, Train Accuracy: 0.9601, Val Accuracy: 0.7344, Iter Time: 0.38s\n",
      "Epoch [25/100], Train Loss: 0.0665, Train Accuracy: 0.9792, Val Accuracy: 0.6875, Iter Time: 0.37s\n",
      "Epoch [30/100], Train Loss: 0.0292, Train Accuracy: 0.9948, Val Accuracy: 0.7188, Iter Time: 0.39s\n",
      "Epoch [35/100], Train Loss: 0.0202, Train Accuracy: 0.9931, Val Accuracy: 0.7188, Iter Time: 0.39s\n",
      "Epoch [40/100], Train Loss: 0.0139, Train Accuracy: 0.9948, Val Accuracy: 0.7344, Iter Time: 0.41s\n",
      "Epoch [45/100], Train Loss: 0.0993, Train Accuracy: 0.9844, Val Accuracy: 0.6562, Iter Time: 0.40s\n",
      "Early stopping after 48 epochs\n",
      "Fold 1 Best Validation Accuracy: 0.7500\n",
      "Fold 2/10\n",
      "Epoch [5/100], Train Loss: 1.1820, Train Accuracy: 0.5938, Val Accuracy: 0.5312, Iter Time: 0.36s\n",
      "Epoch [10/100], Train Loss: 0.4654, Train Accuracy: 0.8455, Val Accuracy: 0.7500, Iter Time: 0.42s\n",
      "Epoch [15/100], Train Loss: 0.1821, Train Accuracy: 0.9497, Val Accuracy: 0.7812, Iter Time: 0.39s\n",
      "Epoch [20/100], Train Loss: 0.2426, Train Accuracy: 0.9306, Val Accuracy: 0.7969, Iter Time: 0.38s\n",
      "Epoch [25/100], Train Loss: 0.0597, Train Accuracy: 0.9809, Val Accuracy: 0.7969, Iter Time: 0.38s\n",
      "Epoch [30/100], Train Loss: 0.0793, Train Accuracy: 0.9826, Val Accuracy: 0.7812, Iter Time: 0.37s\n",
      "Epoch [35/100], Train Loss: 0.0371, Train Accuracy: 0.9896, Val Accuracy: 0.8281, Iter Time: 0.38s\n",
      "Early stopping after 36 epochs\n",
      "Fold 2 Best Validation Accuracy: 0.8438\n",
      "Fold 3/10\n",
      "Epoch [5/100], Train Loss: 1.2107, Train Accuracy: 0.5729, Val Accuracy: 0.4688, Iter Time: 0.40s\n",
      "Epoch [10/100], Train Loss: 0.4684, Train Accuracy: 0.8351, Val Accuracy: 0.7188, Iter Time: 0.37s\n",
      "Epoch [15/100], Train Loss: 0.3184, Train Accuracy: 0.8924, Val Accuracy: 0.7031, Iter Time: 0.37s\n",
      "Epoch [20/100], Train Loss: 0.0904, Train Accuracy: 0.9774, Val Accuracy: 0.7656, Iter Time: 0.38s\n",
      "Epoch [25/100], Train Loss: 0.0580, Train Accuracy: 0.9844, Val Accuracy: 0.7969, Iter Time: 0.40s\n",
      "Epoch [30/100], Train Loss: 0.2060, Train Accuracy: 0.9497, Val Accuracy: 0.7500, Iter Time: 0.38s\n",
      "Early stopping after 33 epochs\n",
      "Fold 3 Best Validation Accuracy: 0.8281\n",
      "Fold 4/10\n",
      "Epoch [5/100], Train Loss: 1.0319, Train Accuracy: 0.6337, Val Accuracy: 0.4688, Iter Time: 0.38s\n",
      "Epoch [10/100], Train Loss: 0.4382, Train Accuracy: 0.8628, Val Accuracy: 0.6875, Iter Time: 0.35s\n",
      "Epoch [15/100], Train Loss: 0.2364, Train Accuracy: 0.9236, Val Accuracy: 0.7500, Iter Time: 0.36s\n",
      "Epoch [20/100], Train Loss: 0.0941, Train Accuracy: 0.9722, Val Accuracy: 0.7344, Iter Time: 0.39s\n",
      "Epoch [25/100], Train Loss: 0.1932, Train Accuracy: 0.9601, Val Accuracy: 0.7344, Iter Time: 0.38s\n",
      "Early stopping after 29 epochs\n",
      "Fold 4 Best Validation Accuracy: 0.7812\n",
      "Fold 5/10\n",
      "Epoch [5/100], Train Loss: 1.0504, Train Accuracy: 0.6684, Val Accuracy: 0.5156, Iter Time: 0.37s\n",
      "Epoch [10/100], Train Loss: 0.3759, Train Accuracy: 0.8715, Val Accuracy: 0.5781, Iter Time: 0.42s\n",
      "Epoch [15/100], Train Loss: 0.1319, Train Accuracy: 0.9653, Val Accuracy: 0.6562, Iter Time: 0.37s\n",
      "Epoch [20/100], Train Loss: 0.0907, Train Accuracy: 0.9740, Val Accuracy: 0.7812, Iter Time: 0.37s\n",
      "Epoch [25/100], Train Loss: 0.0830, Train Accuracy: 0.9740, Val Accuracy: 0.7344, Iter Time: 0.36s\n",
      "Epoch [30/100], Train Loss: 0.0648, Train Accuracy: 0.9792, Val Accuracy: 0.7500, Iter Time: 0.38s\n",
      "Epoch [35/100], Train Loss: 0.0261, Train Accuracy: 0.9931, Val Accuracy: 0.7500, Iter Time: 0.40s\n",
      "Early stopping after 35 epochs\n",
      "Fold 5 Best Validation Accuracy: 0.7812\n",
      "Fold 6/10\n",
      "Epoch [5/100], Train Loss: 1.2003, Train Accuracy: 0.5868, Val Accuracy: 0.5781, Iter Time: 0.37s\n",
      "Epoch [10/100], Train Loss: 0.4261, Train Accuracy: 0.8611, Val Accuracy: 0.6562, Iter Time: 0.38s\n",
      "Epoch [15/100], Train Loss: 0.1825, Train Accuracy: 0.9410, Val Accuracy: 0.7812, Iter Time: 0.39s\n",
      "Epoch [20/100], Train Loss: 0.0762, Train Accuracy: 0.9826, Val Accuracy: 0.8594, Iter Time: 0.37s\n",
      "Epoch [25/100], Train Loss: 0.1020, Train Accuracy: 0.9774, Val Accuracy: 0.7656, Iter Time: 0.37s\n",
      "Epoch [30/100], Train Loss: 0.1103, Train Accuracy: 0.9635, Val Accuracy: 0.8125, Iter Time: 0.40s\n",
      "Epoch [35/100], Train Loss: 0.0499, Train Accuracy: 0.9861, Val Accuracy: 0.7656, Iter Time: 0.38s\n",
      "Early stopping after 35 epochs\n",
      "Fold 6 Best Validation Accuracy: 0.8594\n",
      "Fold 7/10\n",
      "Epoch [5/100], Train Loss: 1.1765, Train Accuracy: 0.5868, Val Accuracy: 0.5312, Iter Time: 0.38s\n",
      "Epoch [10/100], Train Loss: 0.4391, Train Accuracy: 0.8576, Val Accuracy: 0.7188, Iter Time: 0.37s\n",
      "Epoch [15/100], Train Loss: 0.1716, Train Accuracy: 0.9427, Val Accuracy: 0.7500, Iter Time: 0.39s\n",
      "Epoch [20/100], Train Loss: 0.1817, Train Accuracy: 0.9514, Val Accuracy: 0.7812, Iter Time: 0.40s\n",
      "Epoch [25/100], Train Loss: 0.0624, Train Accuracy: 0.9826, Val Accuracy: 0.7969, Iter Time: 0.37s\n",
      "Epoch [30/100], Train Loss: 0.0320, Train Accuracy: 0.9913, Val Accuracy: 0.7969, Iter Time: 0.38s\n",
      "Epoch [35/100], Train Loss: 0.1148, Train Accuracy: 0.9670, Val Accuracy: 0.7344, Iter Time: 0.38s\n",
      "Epoch [40/100], Train Loss: 0.0208, Train Accuracy: 0.9983, Val Accuracy: 0.7812, Iter Time: 0.37s\n",
      "Early stopping after 41 epochs\n",
      "Fold 7 Best Validation Accuracy: 0.8594\n",
      "Fold 8/10\n",
      "Epoch [5/100], Train Loss: 1.1445, Train Accuracy: 0.6267, Val Accuracy: 0.5000, Iter Time: 0.39s\n",
      "Epoch [10/100], Train Loss: 0.4917, Train Accuracy: 0.8351, Val Accuracy: 0.6719, Iter Time: 0.39s\n",
      "Epoch [15/100], Train Loss: 0.1638, Train Accuracy: 0.9444, Val Accuracy: 0.8750, Iter Time: 0.38s\n",
      "Epoch [20/100], Train Loss: 0.1173, Train Accuracy: 0.9757, Val Accuracy: 0.8906, Iter Time: 0.39s\n",
      "Epoch [25/100], Train Loss: 0.0469, Train Accuracy: 0.9913, Val Accuracy: 0.9062, Iter Time: 0.38s\n",
      "Epoch [30/100], Train Loss: 0.2470, Train Accuracy: 0.9288, Val Accuracy: 0.8281, Iter Time: 0.39s\n",
      "Epoch [35/100], Train Loss: 0.0449, Train Accuracy: 0.9844, Val Accuracy: 0.8750, Iter Time: 0.38s\n",
      "Early stopping after 39 epochs\n",
      "Fold 8 Best Validation Accuracy: 0.9219\n",
      "Fold 9/10\n",
      "Epoch [5/100], Train Loss: 1.1850, Train Accuracy: 0.5781, Val Accuracy: 0.5156, Iter Time: 0.37s\n",
      "Epoch [10/100], Train Loss: 0.3724, Train Accuracy: 0.8767, Val Accuracy: 0.6875, Iter Time: 0.37s\n",
      "Epoch [15/100], Train Loss: 0.2220, Train Accuracy: 0.9410, Val Accuracy: 0.7969, Iter Time: 0.37s\n",
      "Epoch [20/100], Train Loss: 0.0878, Train Accuracy: 0.9705, Val Accuracy: 0.8438, Iter Time: 0.36s\n",
      "Epoch [25/100], Train Loss: 0.0404, Train Accuracy: 0.9878, Val Accuracy: 0.7969, Iter Time: 0.39s\n",
      "Epoch [30/100], Train Loss: 0.0281, Train Accuracy: 0.9948, Val Accuracy: 0.8281, Iter Time: 0.40s\n",
      "Epoch [35/100], Train Loss: 0.6223, Train Accuracy: 0.8819, Val Accuracy: 0.7344, Iter Time: 0.38s\n",
      "Epoch [40/100], Train Loss: 0.0450, Train Accuracy: 0.9896, Val Accuracy: 0.8594, Iter Time: 0.37s\n",
      "Epoch [45/100], Train Loss: 0.0271, Train Accuracy: 0.9913, Val Accuracy: 0.8594, Iter Time: 0.39s\n",
      "Early stopping after 47 epochs\n",
      "Fold 9 Best Validation Accuracy: 0.8906\n",
      "Fold 10/10\n",
      "Epoch [5/100], Train Loss: 1.1011, Train Accuracy: 0.6024, Val Accuracy: 0.5312, Iter Time: 0.42s\n",
      "Epoch [10/100], Train Loss: 0.5388, Train Accuracy: 0.8316, Val Accuracy: 0.6875, Iter Time: 0.40s\n",
      "Epoch [15/100], Train Loss: 0.2148, Train Accuracy: 0.9375, Val Accuracy: 0.7031, Iter Time: 0.40s\n",
      "Epoch [20/100], Train Loss: 0.1399, Train Accuracy: 0.9462, Val Accuracy: 0.7344, Iter Time: 0.42s\n",
      "Epoch [25/100], Train Loss: 0.0497, Train Accuracy: 0.9878, Val Accuracy: 0.7656, Iter Time: 0.43s\n",
      "Epoch [30/100], Train Loss: 0.2336, Train Accuracy: 0.9479, Val Accuracy: 0.7656, Iter Time: 0.44s\n",
      "Epoch [35/100], Train Loss: 0.0439, Train Accuracy: 0.9826, Val Accuracy: 0.7500, Iter Time: 0.49s\n",
      "Early stopping after 36 epochs\n",
      "Fold 10 Best Validation Accuracy: 0.7969\n"
     ]
    }
   ],
   "source": [
    "# current random state to split the dataset\n",
    "random_state = 42\n",
    "\n",
    "# values for current run\n",
    "train_final_set, test_set = train_test_split(audioDatasetMfcc, test_size=0.2, random_state=random_state)\n",
    "num_epochs = 100\n",
    "main_architecture = \"CNN_LSTM\"\n",
    "currday = datetime.today().strftime('%Y-%m-%d')\n",
    "model_name = f\"model_multiclass_{num_epochs}_{main_architecture}_{currday}.pth\"\n",
    "description = \"2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \\n 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes. Using normalized and denoised custom audio. n_fft=9, hop_length=500\"\n",
    "\n",
    "# Training part\n",
    "fold_stats = train_with_cross_validation(train_final_set, num_epochs, model_name, random_state=random_state)\n",
    "max_val = 0\n",
    "real_num_epochs = 0\n",
    "for fold_stat in fold_stats: #using folds instead of LOO\n",
    "    if fold_stat[1] > max_val:\n",
    "        max_val = fold_stat[1]\n",
    "        real_num_epochs = fold_stat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "680fb321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results!\n",
      "Model: model_multiclass_100_CNN_LSTM_2024-08-26.pth\n",
      "2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \n",
      " 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes. Testing previous approach with custom data. Attempt 2\n",
      "Epochs: 49\n",
      "Accuracy: 0.6894409937888198\n",
      "Precision: 0.7129598506069095\n",
      "Recall: 0.7024024174887347\n",
      "F1 Score: 0.6876353565547113\n"
     ]
    }
   ],
   "source": [
    "# Prediction part\n",
    "prediction = predict_mfcc(test_set, model_name, device, custom=True) #mark \"custom=True\" for using custom audio in project\n",
    "labels_set = [t[2] for t in test_set]\n",
    "final_labels_set = [keys_s[ind] for ind in labels_set]\n",
    "\n",
    "# Metrics calculation\n",
    "accuracy = accuracy_score(final_labels_set, prediction[0])\n",
    "precision = precision_score(final_labels_set, prediction[0], average='macro')\n",
    "recall = recall_score(final_labels_set, prediction[0], average='macro')\n",
    "f1 = sklearn.metrics.f1_score(final_labels_set, prediction[0], average='macro')\n",
    "\n",
    "# Save in csv file\n",
    "save_csv(model_name, real_num_epochs, description, accuracy, precision, recall, f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Final Results!\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(description)\n",
    "print(f\"Epochs: {real_num_epochs}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cda12c04ba1a39d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:46:13.060776Z",
     "start_time": "2024-08-21T21:46:13.057310Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def empty_file(csv_file_path):\n",
    "    # Read the header (first row) of the CSV file\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Read the first row (header)\n",
    "    \n",
    "    # Write only the header back to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)  # Wr`ite the header back to the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b5aa7e7268b306a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:46:13.698178Z",
     "start_time": "2024-08-21T21:46:13.695766Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty_file('model_comparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
