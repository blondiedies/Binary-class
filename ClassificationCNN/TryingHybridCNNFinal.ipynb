{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a122adee9a39c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.757210Z",
     "start_time": "2024-08-21T17:56:54.457070Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad2373f64ed7deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.764952Z",
     "start_time": "2024-08-21T17:56:56.763360Z"
    }
   },
   "outputs": [],
   "source": [
    "# waveform function for me to not bang my keyboard\n",
    "def disp_waveform(signal, sr=None, color='blue'):\n",
    "    plt.figure(figsize=(7,2))\n",
    "    return librosa.display.waveshow(signal, sr=sr, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.767755Z",
     "start_time": "2024-08-21T17:56:56.765455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, n_fft, hop_length, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        disp_waveform(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        disp_waveform(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        disp_waveform(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*hop_length) + n_fft//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            # strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            # keystroke = transform(keystroke)\n",
    "            strokes.append(keystroke)\n",
    "            if show:\n",
    "                disp_waveform(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c33893a14fb819c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.814715Z",
     "start_time": "2024-08-21T17:56:56.768186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants we actually need for the task\n",
    "MBP_AUDIO_DIR = '../Dataset-for-Binary/base-audio/'\n",
    "MBP_AUDIO_CUSTOM_DIR = '../Dataset-custom-audio/base-audio/' #for custom audio testing\n",
    "keys_s = '1234567890QWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "# keys_s = '12'\n",
    "labels = list(keys_s)\n",
    "keys = ['audio_' + k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}\n",
    "data_dict_t= {'Key':[], 'File':[]} #for custom audio testing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fee322473e2bfe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:56.817344Z",
     "start_time": "2024-08-21T17:56:56.815269Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_fft, hop_length, before, after, keys, custom_audio=False):\n",
    "    for i, File in enumerate(keys):\n",
    "        if custom_audio:\n",
    "            File.replace('audio_', '')\n",
    "            print(File)\n",
    "            loc = MBP_AUDIO_CUSTOM_DIR + File\n",
    "        else:\n",
    "            loc = MBP_AUDIO_DIR + File\n",
    "        samples, sr = librosa.load(loc)\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        strokes = isolator(samples, sr, n_fft, hop_length, before, after, prom, False )\n",
    "        print(f'File {File} length: {len(strokes)}')\n",
    "        label = [labels[i]]*len(strokes)\n",
    "        #works fine here\n",
    "        if custom_audio:\n",
    "            data_dict_t['Key'] += label\n",
    "            data_dict_t['File'] += strokes\n",
    "        else:\n",
    "            data_dict['Key'] += label\n",
    "            data_dict['File'] += strokes\n",
    "\n",
    "\n",
    "    if custom_audio:\n",
    "        df = pd.DataFrame(data_dict_t)\n",
    "    else:\n",
    "        df = pd.DataFrame(data_dict)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if not l in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953e2f0556453dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:58.565620Z",
     "start_time": "2024-08-21T17:56:56.817785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "26 22050\n",
      "25 22050\n",
      "25 22050\n",
      "27 22050\n",
      "26 22050\n",
      "27 22050\n",
      "28 22050\n",
      "28 22050\n",
      "25 22050\n",
      "26 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "27 22050\n",
      "26 22050\n",
      "25 22050\n",
      "27 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "26 22050\n",
      "26 22050\n",
      "25 22050\n",
      "25 22050\n",
      "25 22050\n",
      "26 "
     ]
    }
   ],
   "source": [
    "for key in keys_s:\n",
    "    sample, sr = librosa.load(f'../Dataset-for-Binary/base-audio/audio_{key}.wav')\n",
    "    print(sr)\n",
    "    print(len(isolator(sample, sr, 1024, 225, 2400, 12000, 0.06)), end=' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dd6f724446d4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.171485Z",
     "start_time": "2024-08-21T17:56:58.567245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File audio_1.wav length: 25\n",
      "File audio_2.wav length: 25\n",
      "File audio_3.wav length: 25\n",
      "File audio_4.wav length: 25\n",
      "File audio_5.wav length: 25\n",
      "File audio_6.wav length: 26\n",
      "File audio_7.wav length: 25\n",
      "File audio_8.wav length: 25\n",
      "File audio_9.wav length: 27\n",
      "File audio_0.wav length: 26\n",
      "File audio_Q.wav length: 27\n",
      "File audio_W.wav length: 28\n",
      "File audio_E.wav length: 28\n",
      "File audio_R.wav length: 25\n",
      "File audio_T.wav length: 26\n",
      "File audio_Y.wav length: 25\n",
      "File audio_U.wav length: 25\n",
      "File audio_I.wav length: 25\n",
      "File audio_O.wav length: 25\n",
      "File audio_P.wav length: 25\n",
      "File audio_A.wav length: 25\n",
      "File audio_S.wav length: 25\n",
      "File audio_D.wav length: 25\n",
      "File audio_F.wav length: 27\n",
      "File audio_G.wav length: 26\n",
      "File audio_H.wav length: 25\n",
      "File audio_J.wav length: 27\n",
      "File audio_K.wav length: 25\n",
      "File audio_L.wav length: 25\n",
      "File audio_Z.wav length: 25\n",
      "File audio_X.wav length: 26\n",
      "File audio_C.wav length: 26\n",
      "File audio_V.wav length: 25\n",
      "File audio_B.wav length: 25\n",
      "File audio_N.wav length: 25\n",
      "File audio_M.wav length: 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.00017975706, -0.00012727422, -9.371064e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.000497586, 0.00049031794, 0.0005512878, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0003178973, 0.00034715672, 0.0003719765, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.00268178, 0.0026667328, 0.0026979204, 0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0064755157, 0.0063309446, 0.0053669587, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>35</td>\n",
       "      <td>[-0.250816, -0.25290224, -0.25483984, -0.25665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.13746458, 0.13331985, 0.12892573, 0.1242144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.0017171801, 0.0016756053, 0.0016776036, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>35</td>\n",
       "      <td>[-0.00014814909, -0.00018149172, -0.0002237720...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.00025164883, 0.00018340972, 0.00015876113, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Key                                               File\n",
       "0      0  [-0.00017975706, -0.00012727422, -9.371064e-05...\n",
       "1      0  [0.000497586, 0.00049031794, 0.0005512878, 0.0...\n",
       "2      0  [0.0003178973, 0.00034715672, 0.0003719765, 0....\n",
       "3      0  [0.00268178, 0.0026667328, 0.0026979204, 0.002...\n",
       "4      0  [0.0064755157, 0.0063309446, 0.0053669587, 0.0...\n",
       "..   ...                                                ...\n",
       "916   35  [-0.250816, -0.25290224, -0.25483984, -0.25665...\n",
       "917   35  [0.13746458, 0.13331985, 0.12892573, 0.1242144...\n",
       "918   35  [0.0017171801, 0.0016756053, 0.0016776036, 0.0...\n",
       "919   35  [-0.00014814909, -0.00018149172, -0.0002237720...\n",
       "920   35  [0.00025164883, 0.00018340972, 0.00015876113, ...\n",
       "\n",
       "[921 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_fft = 1024\n",
    "hop_length = 225\n",
    "before = 2400\n",
    "after = 12000\n",
    "mbp_dataset = create_dataset(n_fft, hop_length, before, after, keys)\n",
    "mbp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89e46a8b42021c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.210310Z",
     "start_time": "2024-08-21T17:56:59.172105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,)\n",
      "(20, 29)\n"
     ]
    }
   ],
   "source": [
    "audio_samples = mbp_dataset['File'].values.tolist()\n",
    "labels = mbp_dataset['Key'].values.tolist()\n",
    "\n",
    "audioDataset = np.array(audio_samples, dtype = object)\n",
    "print(audio_samples[0].shape)\n",
    "mfcc = librosa.feature.mfcc(y=audio_samples[0], sr=44100) # shape: (n_mfcc, t)\n",
    "print(mfcc.shape)\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d2cd83eaab0466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.244806Z",
     "start_time": "2024-08-21T17:56:59.217910Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "#       samples_shape = samples.shape\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4) #Max shift (0.4)\n",
    "        random_shift = random.randint(0, shift) #Random number between 0 and 0.4*len(samples)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3598b8c7bcd285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.286280Z",
     "start_time": "2024-08-21T17:56:59.250402Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_shift(samples):\n",
    "    samples = samples.flatten()\n",
    "    shift = int(len(samples) * 0.4) #Max shift (0.4)\n",
    "    random_shift = random.randint(0, shift) #Random number between 0 and 0.4*len(samples)\n",
    "    data_roll = np.roll(samples, random_shift)\n",
    "    return data_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a429af86b3206df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.345608Z",
     "start_time": "2024-08-21T17:56:59.308102Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=samples, sr=44100, n_mels=64, n_fft=1024, hop_length=225)\n",
    "        mel_spec_resized = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "        mel_spec_resized = np.expand_dims(mel_spec_resized, axis=0)\n",
    "        return torch.tensor(mel_spec_resized)\n",
    "\n",
    "\n",
    "class ToMelSpectrogramMfcc:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=samples, sr=44100, n_mels=64, n_fft=n_fft, hop_length=hop_length)\n",
    "        mel_spec = librosa.feature.mfcc(S=librosa.power_to_db(mel_spec))\n",
    "        mel_spec_resized = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "        mel_spec_resized = np.expand_dims(mel_spec_resized, axis=0)\n",
    "\n",
    "        return torch.tensor(mel_spec_resized)\n",
    "\n",
    "\n",
    "class ToMfcc:\n",
    "    def __init__(self, audio_length=14400):\n",
    "        self.audio_length = audio_length\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        if len(samples) > self.audio_length:\n",
    "            samples = samples[:self.audio_length]\n",
    "        elif len(samples) < self.audio_length:\n",
    "            samples = np.pad(samples, (0, self.audio_length - len(samples)), mode='constant')\n",
    "        \n",
    "        mfcc_spec = librosa.feature.mfcc(y=samples, sr=44100)\n",
    "        mfcc_spec = np.transpose(mfcc_spec)\n",
    "        return torch.tensor(mfcc_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f019fc2bc0e25204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:56:59.347730Z",
     "start_time": "2024-08-21T17:56:59.346203Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = Compose([ToMelSpectrogram()])\n",
    "transform_mfcc = Compose([ToMfcc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b3b3ca9f37f4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:01.583816Z",
     "start_time": "2024-08-21T17:57:01.569876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842\n",
      "1842\n"
     ]
    }
   ],
   "source": [
    "audio_samples_new = audio_samples.copy() # audio samples CNN\n",
    "\n",
    "for i, sample in enumerate(audio_samples):\n",
    "    audio_samples_new.append(time_shift(sample))\n",
    "    labels.append(labels[i])\n",
    "    \n",
    "# convert labels to a numpy array\n",
    "labels = np.array(labels)\n",
    "print(len(audio_samples_new))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9e929216f37f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.494105Z",
     "start_time": "2024-08-21T17:57:01.586778Z"
    }
   },
   "outputs": [],
   "source": [
    "audioDatasetFin, audioDatasetMfcc = [], []\n",
    "\n",
    "for i in range(len(audio_samples_new)):\n",
    "    transformed_sample = transform(audio_samples_new[i])\n",
    "    transformed_mfcc = transform_mfcc(audio_samples_new[i])\n",
    "    audioDatasetFin.append((transformed_sample, labels[i]))\n",
    "    audioDatasetMfcc.append((transformed_sample, transformed_mfcc, labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d1788d46fe597f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.510318Z",
     "start_time": "2024-08-21T17:57:09.496003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioDatasetFin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf735153a104afec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.545687Z",
     "start_time": "2024-08-21T17:57:09.516010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioDatasetMfcc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c53f1c392a2eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.562851Z",
     "start_time": "2024-08-21T17:57:09.555932Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MfccLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2, num_classes=36):\n",
    "        super(MfccLSTM, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.LazyLinear(64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "    \n",
    "        self.fc3 = nn.LazyLinear(128)\n",
    "        self.final_lstm = nn.LSTM(1, 64, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.LazyLinear(num_classes)\n",
    "    \n",
    "    def forward(self, image_input, sequence_input):\n",
    "        # must return shape (batch_size, num_classes) \n",
    "        # batch_size: right now is 16\n",
    "        # num_classes: right now is 36\n",
    "        x1 = self.conv(image_input)\n",
    "        out1, _ = self.lstm(sequence_input)\n",
    "        out1_dp = self.dropout(out1)\n",
    "        # print(f'output of first lstm: {out1_dp.shape[1:]}')\n",
    "        out2, _ = self.lstm2(out1_dp[:, -1, :])\n",
    "        out2_dp = self.dropout(out2)\n",
    "        # print(f'output of second lstm: {out2_dp.shape[1:]}')\n",
    "        x2 = self.fc2(self.fc1(out2_dp))\n",
    "        x3 = torch.cat((x1, x2), 1)\n",
    "        # print(f'output of concatenation: {x3.shape[1:]}')\n",
    "        # x = self.fc(final_out[:, -1, :])\n",
    "        x = self.fc(x3)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "876758bd07bc26b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:57:09.568636Z",
     "start_time": "2024-08-21T17:57:09.564462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=36):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.LazyLinear(512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1ab811f0d1abfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:03.746585Z",
     "start_time": "2024-08-21T21:43:03.734939Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_with_cross_validation(dataset, num_epochs, model_name, patience=15, random_state=42, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f'Fold {fold+1}/{n_splits}')\n",
    "        \n",
    "        # Split the dataset into training and validation sets\n",
    "        train_set = Subset(dataset, train_idx)\n",
    "        val_set = Subset(dataset, val_idx)\n",
    "        train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=16, shuffle=True)\n",
    "        \n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = MfccLSTM(input_size=20, hidden_size=32, num_classes=36, output_size=64)\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        best_val_acc, epochs_no_imp = 0, 0\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            tic = time.perf_counter()\n",
    "            \n",
    "            for images, sequences, labels in train_loader:\n",
    "                images = images.to(device)\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #converting labels to Long to avoid error \"not implemented for Int\"\n",
    "                labels = labels.long()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images, sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted_train = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted_train == labels).sum().item()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            toc = time.perf_counter()\n",
    "            time_taken = toc - tic\n",
    "            \n",
    "            epoch_train_loss /= len(train_loader.dataset)\n",
    "            train_accuracy = correct_train / total_train\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            # Evaluation of the model\n",
    "            model.eval()\n",
    "            total, correct = 0, 0\n",
    "            for images, sequences, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images, sequences)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_accuracy = correct / total\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Iter Time: {time_taken:.2f}s\")\n",
    "                \n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                epochs_no_imp = 0\n",
    "                best_model_state = model.state_dict()  # Save the best model\n",
    "            else:\n",
    "                epochs_no_imp += 1\n",
    "            if epochs_no_imp >= patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                model.load_state_dict(best_model_state)  # Load the best model\n",
    "                break\n",
    "        \n",
    "        fold_results.append((epoch+1, best_val_acc))\n",
    "        print(f'Fold {fold+1} Best Validation Accuracy: {best_val_acc:.4f}')\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e58aef22cf15f974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:05.428428Z",
     "start_time": "2024-08-21T21:43:05.425143Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_mfcc(dataset, model_path, device_external):\n",
    "    images_test_set = [t[0] for t in dataset]\n",
    "    sequences_test_set = [t[1] for t in dataset]\n",
    "    \n",
    "    images = torch.stack(images_test_set)\n",
    "    sequences = torch.stack(sequences_test_set)\n",
    "    device = torch.device(device_external) #default to mps\n",
    "    images = images.to(device)\n",
    "    sequences = sequences.to(device)\n",
    "    model = MfccLSTM(input_size=20, hidden_size=32, num_classes=36, output_size=64)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images, sequences)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    pred = []\n",
    "    keyss = '1234567890QWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "    phrase = predicted.tolist()\n",
    "    for i in range(len(phrase)):\n",
    "        pred.append(keyss[phrase[i]])\n",
    "\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea4576ee7857b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:43:06.012807Z",
     "start_time": "2024-08-21T21:43:06.010208Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_csv(model_name, num_epochs, description, accuracy, precision, recall, f1_score):\n",
    "    csv_file_path = 'model_comparison.csv'\n",
    "    \n",
    "    # Read the existing CSV file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, create an empty DataFrame with the correct columns\n",
    "        df = pd.DataFrame(columns=['Datetime', 'Name', 'Epochs', 'Description', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "        \n",
    "    # Data to append\n",
    "    current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Remove newline characters from the description\n",
    "    description = description.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # Create a new column with the relevant information\n",
    "    new_data = {\n",
    "        'Datetime': [current_datetime],\n",
    "        'Name': [model_name],\n",
    "        'Epochs': [num_epochs],\n",
    "        'Description': [description],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1': [f1_score],\n",
    "    }\n",
    "    \n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7407a641de41b299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:44:33.450713Z",
     "start_time": "2024-08-21T21:43:10.233998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kat\\.conda\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 1.8153, Train Accuracy: 0.4332, Val Accuracy: 0.4122, Iter Time: 0.82s\n",
      "Epoch [10/100], Train Loss: 1.0048, Train Accuracy: 0.6845, Val Accuracy: 0.5541, Iter Time: 0.83s\n",
      "Epoch [15/100], Train Loss: 0.6547, Train Accuracy: 0.7894, Val Accuracy: 0.5270, Iter Time: 0.81s\n",
      "Epoch [20/100], Train Loss: 0.3757, Train Accuracy: 0.8838, Val Accuracy: 0.6284, Iter Time: 0.81s\n",
      "Epoch [25/100], Train Loss: 0.2819, Train Accuracy: 0.9147, Val Accuracy: 0.6419, Iter Time: 0.78s\n",
      "Epoch [30/100], Train Loss: 0.2046, Train Accuracy: 0.9374, Val Accuracy: 0.6486, Iter Time: 0.79s\n",
      "Epoch [35/100], Train Loss: 0.1189, Train Accuracy: 0.9683, Val Accuracy: 0.7027, Iter Time: 0.78s\n",
      "Epoch [40/100], Train Loss: 0.1152, Train Accuracy: 0.9675, Val Accuracy: 0.6824, Iter Time: 0.78s\n",
      "Epoch [45/100], Train Loss: 0.0664, Train Accuracy: 0.9834, Val Accuracy: 0.7365, Iter Time: 0.80s\n",
      "Epoch [50/100], Train Loss: 0.2254, Train Accuracy: 0.9313, Val Accuracy: 0.6824, Iter Time: 0.80s\n",
      "Epoch [55/100], Train Loss: 0.0476, Train Accuracy: 0.9887, Val Accuracy: 0.7568, Iter Time: 0.79s\n",
      "Epoch [60/100], Train Loss: 0.0385, Train Accuracy: 0.9879, Val Accuracy: 0.7973, Iter Time: 0.79s\n",
      "Epoch [65/100], Train Loss: 0.0426, Train Accuracy: 0.9894, Val Accuracy: 0.7703, Iter Time: 0.78s\n",
      "Epoch [70/100], Train Loss: 0.2649, Train Accuracy: 0.9268, Val Accuracy: 0.6757, Iter Time: 0.82s\n",
      "Epoch [75/100], Train Loss: 0.0401, Train Accuracy: 0.9864, Val Accuracy: 0.7500, Iter Time: 0.83s\n",
      "Early stopping after 75 epochs\n",
      "Fold 1 Best Validation Accuracy: 0.7973\n",
      "Fold 2/10\n",
      "Epoch [5/100], Train Loss: 1.9143, Train Accuracy: 0.4189, Val Accuracy: 0.4054, Iter Time: 0.83s\n",
      "Epoch [10/100], Train Loss: 0.8861, Train Accuracy: 0.7079, Val Accuracy: 0.6216, Iter Time: 0.79s\n",
      "Epoch [15/100], Train Loss: 0.5463, Train Accuracy: 0.8257, Val Accuracy: 0.6959, Iter Time: 0.81s\n",
      "Epoch [20/100], Train Loss: 0.3423, Train Accuracy: 0.8981, Val Accuracy: 0.7297, Iter Time: 0.81s\n",
      "Epoch [25/100], Train Loss: 0.3145, Train Accuracy: 0.9102, Val Accuracy: 0.6959, Iter Time: 0.80s\n",
      "Epoch [30/100], Train Loss: 0.2602, Train Accuracy: 0.9328, Val Accuracy: 0.6959, Iter Time: 0.77s\n",
      "Epoch [35/100], Train Loss: 0.1556, Train Accuracy: 0.9570, Val Accuracy: 0.7568, Iter Time: 0.76s\n",
      "Epoch [40/100], Train Loss: 0.1580, Train Accuracy: 0.9577, Val Accuracy: 0.7635, Iter Time: 0.83s\n",
      "Epoch [45/100], Train Loss: 0.0834, Train Accuracy: 0.9743, Val Accuracy: 0.7365, Iter Time: 0.78s\n",
      "Epoch [50/100], Train Loss: 0.1245, Train Accuracy: 0.9668, Val Accuracy: 0.7973, Iter Time: 0.80s\n",
      "Epoch [55/100], Train Loss: 0.0514, Train Accuracy: 0.9872, Val Accuracy: 0.7973, Iter Time: 0.80s\n",
      "Epoch [60/100], Train Loss: 0.2472, Train Accuracy: 0.9336, Val Accuracy: 0.7500, Iter Time: 0.80s\n",
      "Epoch [65/100], Train Loss: 0.1143, Train Accuracy: 0.9698, Val Accuracy: 0.7973, Iter Time: 0.85s\n",
      "Early stopping after 65 epochs\n",
      "Fold 2 Best Validation Accuracy: 0.7973\n",
      "Fold 3/10\n",
      "Epoch [5/100], Train Loss: 1.8445, Train Accuracy: 0.4294, Val Accuracy: 0.3378, Iter Time: 0.78s\n",
      "Epoch [10/100], Train Loss: 0.9569, Train Accuracy: 0.6687, Val Accuracy: 0.5068, Iter Time: 0.78s\n",
      "Epoch [15/100], Train Loss: 0.5907, Train Accuracy: 0.8075, Val Accuracy: 0.5811, Iter Time: 0.80s\n",
      "Epoch [20/100], Train Loss: 0.3231, Train Accuracy: 0.8981, Val Accuracy: 0.5946, Iter Time: 0.77s\n",
      "Epoch [25/100], Train Loss: 0.2435, Train Accuracy: 0.9328, Val Accuracy: 0.6014, Iter Time: 0.78s\n",
      "Epoch [30/100], Train Loss: 0.1861, Train Accuracy: 0.9509, Val Accuracy: 0.5811, Iter Time: 0.78s\n",
      "Epoch [35/100], Train Loss: 0.1235, Train Accuracy: 0.9653, Val Accuracy: 0.6554, Iter Time: 0.78s\n",
      "Epoch [40/100], Train Loss: 0.1107, Train Accuracy: 0.9698, Val Accuracy: 0.6284, Iter Time: 0.81s\n",
      "Epoch [45/100], Train Loss: 0.1484, Train Accuracy: 0.9698, Val Accuracy: 0.6284, Iter Time: 0.78s\n",
      "Epoch [50/100], Train Loss: 0.2067, Train Accuracy: 0.9555, Val Accuracy: 0.6419, Iter Time: 0.80s\n",
      "Epoch [55/100], Train Loss: 0.0914, Train Accuracy: 0.9774, Val Accuracy: 0.6284, Iter Time: 0.78s\n",
      "Early stopping after 56 epochs\n",
      "Fold 3 Best Validation Accuracy: 0.6959\n",
      "Fold 4/10\n",
      "Epoch [5/100], Train Loss: 1.8027, Train Accuracy: 0.4351, Val Accuracy: 0.3333, Iter Time: 0.76s\n",
      "Epoch [10/100], Train Loss: 0.9607, Train Accuracy: 0.6863, Val Accuracy: 0.5238, Iter Time: 0.80s\n",
      "Epoch [15/100], Train Loss: 0.5486, Train Accuracy: 0.8258, Val Accuracy: 0.6122, Iter Time: 0.77s\n",
      "Epoch [20/100], Train Loss: 0.3492, Train Accuracy: 0.8824, Val Accuracy: 0.5714, Iter Time: 0.77s\n",
      "Epoch [25/100], Train Loss: 0.2559, Train Accuracy: 0.9268, Val Accuracy: 0.6190, Iter Time: 0.79s\n",
      "Epoch [30/100], Train Loss: 0.2066, Train Accuracy: 0.9359, Val Accuracy: 0.6667, Iter Time: 0.76s\n",
      "Epoch [35/100], Train Loss: 0.1492, Train Accuracy: 0.9600, Val Accuracy: 0.6667, Iter Time: 0.79s\n",
      "Epoch [40/100], Train Loss: 0.1254, Train Accuracy: 0.9729, Val Accuracy: 0.6395, Iter Time: 0.79s\n",
      "Early stopping after 41 epochs\n",
      "Fold 4 Best Validation Accuracy: 0.7143\n",
      "Fold 5/10\n",
      "Epoch [5/100], Train Loss: 1.7774, Train Accuracy: 0.4532, Val Accuracy: 0.3537, Iter Time: 0.79s\n",
      "Epoch [10/100], Train Loss: 0.9150, Train Accuracy: 0.7044, Val Accuracy: 0.4830, Iter Time: 0.79s\n",
      "Epoch [15/100], Train Loss: 0.5963, Train Accuracy: 0.8167, Val Accuracy: 0.5510, Iter Time: 0.80s\n",
      "Epoch [20/100], Train Loss: 0.3218, Train Accuracy: 0.8929, Val Accuracy: 0.5782, Iter Time: 0.81s\n",
      "Epoch [25/100], Train Loss: 0.2587, Train Accuracy: 0.9246, Val Accuracy: 0.5918, Iter Time: 0.81s\n",
      "Epoch [30/100], Train Loss: 0.1894, Train Accuracy: 0.9517, Val Accuracy: 0.5986, Iter Time: 0.80s\n",
      "Epoch [35/100], Train Loss: 0.1222, Train Accuracy: 0.9653, Val Accuracy: 0.5782, Iter Time: 0.79s\n",
      "Epoch [40/100], Train Loss: 0.1169, Train Accuracy: 0.9698, Val Accuracy: 0.5986, Iter Time: 0.78s\n",
      "Epoch [45/100], Train Loss: 0.2572, Train Accuracy: 0.9329, Val Accuracy: 0.5986, Iter Time: 0.77s\n",
      "Epoch [50/100], Train Loss: 0.0366, Train Accuracy: 0.9894, Val Accuracy: 0.6190, Iter Time: 0.78s\n",
      "Epoch [55/100], Train Loss: 0.2097, Train Accuracy: 0.9525, Val Accuracy: 0.5374, Iter Time: 0.78s\n",
      "Epoch [60/100], Train Loss: 0.0473, Train Accuracy: 0.9887, Val Accuracy: 0.6667, Iter Time: 0.79s\n",
      "Epoch [65/100], Train Loss: 0.0839, Train Accuracy: 0.9751, Val Accuracy: 0.6122, Iter Time: 0.80s\n",
      "Epoch [70/100], Train Loss: 0.0682, Train Accuracy: 0.9864, Val Accuracy: 0.6259, Iter Time: 0.79s\n",
      "Epoch [75/100], Train Loss: 0.0239, Train Accuracy: 0.9947, Val Accuracy: 0.6735, Iter Time: 0.79s\n",
      "Epoch [80/100], Train Loss: 0.0222, Train Accuracy: 0.9925, Val Accuracy: 0.6735, Iter Time: 0.77s\n",
      "Epoch [85/100], Train Loss: 0.0136, Train Accuracy: 0.9962, Val Accuracy: 0.6531, Iter Time: 0.79s\n",
      "Epoch [90/100], Train Loss: 0.1159, Train Accuracy: 0.9683, Val Accuracy: 0.6463, Iter Time: 0.80s\n",
      "Early stopping after 92 epochs\n",
      "Fold 5 Best Validation Accuracy: 0.7007\n",
      "Fold 6/10\n",
      "Epoch [5/100], Train Loss: 1.8461, Train Accuracy: 0.4276, Val Accuracy: 0.3605, Iter Time: 0.79s\n",
      "Epoch [10/100], Train Loss: 1.0089, Train Accuracy: 0.6682, Val Accuracy: 0.4082, Iter Time: 0.88s\n",
      "Epoch [15/100], Train Loss: 0.6316, Train Accuracy: 0.7851, Val Accuracy: 0.4898, Iter Time: 0.84s\n",
      "Epoch [20/100], Train Loss: 0.4326, Train Accuracy: 0.8529, Val Accuracy: 0.5374, Iter Time: 0.82s\n",
      "Epoch [25/100], Train Loss: 0.3193, Train Accuracy: 0.9065, Val Accuracy: 0.5850, Iter Time: 0.84s\n",
      "Epoch [30/100], Train Loss: 0.1948, Train Accuracy: 0.9442, Val Accuracy: 0.5918, Iter Time: 0.79s\n",
      "Epoch [35/100], Train Loss: 0.1909, Train Accuracy: 0.9404, Val Accuracy: 0.5510, Iter Time: 0.79s\n",
      "Epoch [40/100], Train Loss: 0.2163, Train Accuracy: 0.9359, Val Accuracy: 0.5714, Iter Time: 0.79s\n",
      "Epoch [45/100], Train Loss: 0.0673, Train Accuracy: 0.9781, Val Accuracy: 0.5850, Iter Time: 0.78s\n",
      "Epoch [50/100], Train Loss: 0.4214, Train Accuracy: 0.8989, Val Accuracy: 0.5850, Iter Time: 0.77s\n",
      "Epoch [55/100], Train Loss: 0.0746, Train Accuracy: 0.9796, Val Accuracy: 0.5578, Iter Time: 0.78s\n",
      "Early stopping after 58 epochs\n",
      "Fold 6 Best Validation Accuracy: 0.6395\n",
      "Fold 7/10\n",
      "Epoch [5/100], Train Loss: 1.7920, Train Accuracy: 0.4344, Val Accuracy: 0.4014, Iter Time: 0.79s\n",
      "Epoch [10/100], Train Loss: 0.9437, Train Accuracy: 0.6983, Val Accuracy: 0.4898, Iter Time: 0.77s\n",
      "Epoch [15/100], Train Loss: 0.5027, Train Accuracy: 0.8454, Val Accuracy: 0.5986, Iter Time: 0.78s\n",
      "Epoch [20/100], Train Loss: 0.3212, Train Accuracy: 0.9095, Val Accuracy: 0.6327, Iter Time: 0.78s\n",
      "Epoch [25/100], Train Loss: 0.2056, Train Accuracy: 0.9427, Val Accuracy: 0.6395, Iter Time: 0.79s\n",
      "Epoch [30/100], Train Loss: 0.2297, Train Accuracy: 0.9321, Val Accuracy: 0.6122, Iter Time: 0.77s\n",
      "Epoch [35/100], Train Loss: 0.1275, Train Accuracy: 0.9646, Val Accuracy: 0.6327, Iter Time: 0.78s\n",
      "Epoch [40/100], Train Loss: 0.0837, Train Accuracy: 0.9781, Val Accuracy: 0.6667, Iter Time: 0.79s\n",
      "Early stopping after 43 epochs\n",
      "Fold 7 Best Validation Accuracy: 0.6735\n",
      "Fold 8/10\n",
      "Epoch [5/100], Train Loss: 1.8341, Train Accuracy: 0.4208, Val Accuracy: 0.2993, Iter Time: 0.79s\n",
      "Epoch [10/100], Train Loss: 0.9849, Train Accuracy: 0.6848, Val Accuracy: 0.5510, Iter Time: 0.77s\n",
      "Epoch [15/100], Train Loss: 0.5830, Train Accuracy: 0.8152, Val Accuracy: 0.5578, Iter Time: 0.78s\n",
      "Epoch [20/100], Train Loss: 0.5238, Train Accuracy: 0.8250, Val Accuracy: 0.5306, Iter Time: 0.78s\n",
      "Epoch [25/100], Train Loss: 0.2833, Train Accuracy: 0.9178, Val Accuracy: 0.5442, Iter Time: 0.78s\n",
      "Epoch [30/100], Train Loss: 0.1841, Train Accuracy: 0.9427, Val Accuracy: 0.6327, Iter Time: 0.79s\n",
      "Epoch [35/100], Train Loss: 0.1937, Train Accuracy: 0.9434, Val Accuracy: 0.5918, Iter Time: 0.77s\n",
      "Epoch [40/100], Train Loss: 0.1791, Train Accuracy: 0.9487, Val Accuracy: 0.5782, Iter Time: 0.77s\n",
      "Epoch [45/100], Train Loss: 0.0706, Train Accuracy: 0.9796, Val Accuracy: 0.5714, Iter Time: 0.78s\n",
      "Early stopping after 45 epochs\n",
      "Fold 8 Best Validation Accuracy: 0.6327\n",
      "Fold 9/10\n",
      "Epoch [5/100], Train Loss: 1.9102, Train Accuracy: 0.4020, Val Accuracy: 0.3537, Iter Time: 0.78s\n",
      "Epoch [10/100], Train Loss: 1.0234, Train Accuracy: 0.6885, Val Accuracy: 0.5306, Iter Time: 0.77s\n",
      "Epoch [15/100], Train Loss: 0.5917, Train Accuracy: 0.8190, Val Accuracy: 0.5986, Iter Time: 0.78s\n",
      "Epoch [20/100], Train Loss: 0.3954, Train Accuracy: 0.8763, Val Accuracy: 0.6190, Iter Time: 0.76s\n",
      "Epoch [25/100], Train Loss: 0.2920, Train Accuracy: 0.9012, Val Accuracy: 0.6327, Iter Time: 0.78s\n",
      "Epoch [30/100], Train Loss: 0.2701, Train Accuracy: 0.9170, Val Accuracy: 0.6599, Iter Time: 0.76s\n",
      "Epoch [35/100], Train Loss: 0.1385, Train Accuracy: 0.9638, Val Accuracy: 0.6463, Iter Time: 0.77s\n",
      "Epoch [40/100], Train Loss: 0.0599, Train Accuracy: 0.9842, Val Accuracy: 0.6667, Iter Time: 0.76s\n",
      "Early stopping after 41 epochs\n",
      "Fold 9 Best Validation Accuracy: 0.6871\n",
      "Fold 10/10\n",
      "Epoch [5/100], Train Loss: 1.8380, Train Accuracy: 0.4238, Val Accuracy: 0.3605, Iter Time: 0.78s\n",
      "Epoch [10/100], Train Loss: 0.9272, Train Accuracy: 0.7179, Val Accuracy: 0.5578, Iter Time: 0.77s\n",
      "Epoch [15/100], Train Loss: 0.5271, Train Accuracy: 0.8348, Val Accuracy: 0.6122, Iter Time: 0.77s\n",
      "Epoch [20/100], Train Loss: 0.3384, Train Accuracy: 0.8952, Val Accuracy: 0.6599, Iter Time: 0.83s\n",
      "Epoch [25/100], Train Loss: 0.3406, Train Accuracy: 0.8839, Val Accuracy: 0.6463, Iter Time: 0.76s\n",
      "Epoch [30/100], Train Loss: 0.0988, Train Accuracy: 0.9774, Val Accuracy: 0.6667, Iter Time: 0.76s\n",
      "Epoch [35/100], Train Loss: 0.2027, Train Accuracy: 0.9442, Val Accuracy: 0.6531, Iter Time: 0.73s\n",
      "Epoch [40/100], Train Loss: 0.1207, Train Accuracy: 0.9661, Val Accuracy: 0.7211, Iter Time: 0.75s\n",
      "Epoch [45/100], Train Loss: 0.0831, Train Accuracy: 0.9744, Val Accuracy: 0.6667, Iter Time: 0.75s\n",
      "Epoch [50/100], Train Loss: 0.0412, Train Accuracy: 0.9902, Val Accuracy: 0.6939, Iter Time: 0.74s\n",
      "Epoch [55/100], Train Loss: 0.1560, Train Accuracy: 0.9570, Val Accuracy: 0.6054, Iter Time: 0.73s\n",
      "Early stopping after 55 epochs\n",
      "Fold 10 Best Validation Accuracy: 0.7211\n"
     ]
    }
   ],
   "source": [
    "# current random state to split the dataset\n",
    "random_state = 42\n",
    "\n",
    "# values for current run\n",
    "train_final_set, test_set = train_test_split(audioDatasetMfcc, test_size=0.2, random_state=random_state)\n",
    "num_epochs = 100\n",
    "main_architecture = \"CNN_LSTM\"\n",
    "currday = datetime.today().strftime('%Y-%m-%d')\n",
    "model_name = f\"model_multiclass_{num_epochs}_{main_architecture}_{currday}.pth\"\n",
    "description = \"2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \\n 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes\"\n",
    "\n",
    "# Training part\n",
    "fold_stats = train_with_cross_validation(train_final_set, num_epochs, model_name, random_state=random_state)\n",
    "max_val = 0\n",
    "real_num_epochs = 0\n",
    "for fold_stat in fold_stats: #using folds instead of LOO\n",
    "    if fold_stat[1] > max_val:\n",
    "        max_val = fold_stat[1]\n",
    "        real_num_epochs = fold_stat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "680fb321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results!\n",
      "Model: model_multiclass_100_CNN_LSTM_2024-08-22.pth\n",
      "2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \n",
      " 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes\n",
      "Epochs: 75\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.7017860794176582\n",
      "Recall: 0.6891187130770464\n",
      "F1 Score: 0.6711896824492809\n"
     ]
    }
   ],
   "source": [
    "# Prediction part\n",
    "prediction = predict_mfcc(test_set, model_name, device)\n",
    "labels_set = [t[2] for t in test_set]\n",
    "final_labels_set = [keys_s[ind] for ind in labels_set]\n",
    "\n",
    "# Metrics calculation\n",
    "accuracy = accuracy_score(final_labels_set, prediction[0])\n",
    "precision = precision_score(final_labels_set, prediction[0], average='macro')\n",
    "recall = recall_score(final_labels_set, prediction[0], average='macro')\n",
    "f1 = sklearn.metrics.f1_score(final_labels_set, prediction[0], average='macro')\n",
    "\n",
    "# Save in csv file\n",
    "save_csv(model_name, real_num_epochs, description, accuracy, precision, recall, f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Final Results!\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(description)\n",
    "print(f\"Epochs: {real_num_epochs}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cda12c04ba1a39d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:46:13.060776Z",
     "start_time": "2024-08-21T21:46:13.057310Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def empty_file(csv_file_path):\n",
    "    # Read the header (first row) of the CSV file\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Read the first row (header)\n",
    "    \n",
    "    # Write only the header back to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)  # Wr`ite the header back to the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa7e7268b306a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:46:13.698178Z",
     "start_time": "2024-08-21T21:46:13.695766Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty_file('model_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8e875",
   "metadata": {},
   "source": [
    "# Using custom audio\n",
    "\n",
    "The following code adapts the previous working segment to utilize custom audio recorded by the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23af0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n",
      "5 22050\n",
      "10 22050\n",
      "12 22050\n",
      "4 "
     ]
    }
   ],
   "source": [
    "#Using audio from custom-audio to create the test_set\n",
    "keys_t_s='0123'\n",
    "labels_t = list(keys_t_s)\n",
    "keys_t = [k + '.wav' for k in labels_t]\n",
    "\n",
    "for key in keys_t:\n",
    "    sample_t, sr_t = librosa.load(f'../Dataset-custom-audio/base-audio/{key}')\n",
    "    print(sr_t)\n",
    "    print(len(isolator(sample_t, sr_t, 1024, 225, 2400, 12000, 0.06)), end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4879ba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.wav\n",
      "File 0.wav length: 5\n",
      "1.wav\n",
      "File 1.wav length: 10\n",
      "2.wav\n",
      "File 2.wav length: 12\n",
      "3.wav\n",
      "File 3.wav length: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.00037375191, -0.00084931636, -0.0003490468...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.002790125, 0.002429493, 0.0028012446, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0071788216, 0.00950514, 0.0094512245, 0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0008956681, 0.0018641897, 0.0014872983, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0019487825, 0.0027770896, 0.0022265469, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.00071250077, 2.2120468e-05, -9.1693e-05, -5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0010570893, 0.001612729, 0.0011079775, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.00074728427, 0.00035364152, -0.000746752, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.00097119296, -0.0013671918, -0.00051295897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0030221755, 0.0024853048, 0.0028788152, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Key                                               File\n",
       "0      0  [-0.00037375191, -0.00084931636, -0.0003490468...\n",
       "1      0  [0.002790125, 0.002429493, 0.0028012446, 0.003...\n",
       "2      0  [0.0071788216, 0.00950514, 0.0094512245, 0.016...\n",
       "3      0  [0.0008956681, 0.0018641897, 0.0014872983, 0.0...\n",
       "4      0  [0.0019487825, 0.0027770896, 0.0022265469, 0.0...\n",
       "..   ...                                                ...\n",
       "119    2  [0.00071250077, 2.2120468e-05, -9.1693e-05, -5...\n",
       "120    3  [0.0010570893, 0.001612729, 0.0011079775, 0.00...\n",
       "121    3  [0.00074728427, 0.00035364152, -0.000746752, 0...\n",
       "122    3  [-0.00097119296, -0.0013671918, -0.00051295897...\n",
       "123    3  [0.0030221755, 0.0024853048, 0.0028788152, 0.0...\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbp_dataset_t = create_dataset(n_fft, hop_length, before, after, keys_t, custom_audio=True)\n",
    "mbp_dataset_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a529fa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,)\n",
      "(20, 29)\n"
     ]
    }
   ],
   "source": [
    "audio_samples_t = mbp_dataset_t['File'].values.tolist()\n",
    "labels_t = mbp_dataset_t['Key'].values.tolist()\n",
    "\n",
    "audioDataset_t = np.array(audio_samples_t, dtype = object)\n",
    "print(audio_samples_t[0].shape)\n",
    "mfcc_t = librosa.feature.mfcc(y=audio_samples_t[0], sr=44100) # shape: (n_mfcc, t)\n",
    "print(mfcc_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "feddd053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "audio_samples_new_t = audio_samples_t.copy() # audio samples CNN\n",
    "\n",
    "for i, sample in enumerate(audio_samples_t):\n",
    "    audio_samples_new_t.append(time_shift(sample))\n",
    "    labels_t.append(labels_t[i])\n",
    "    \n",
    "# convert labels to a numpy array\n",
    "labels_t = np.array(labels_t)\n",
    "print(len(audio_samples_new_t))\n",
    "print(len(labels_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5a0a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioDatasetFin_t, audioDatasetMfcc_t = [], []\n",
    "\n",
    "for i in range(len(audio_samples_new_t)):\n",
    "    transformed_sample_t = transform(audio_samples_new_t[i])\n",
    "    transformed_mfcc_t = transform_mfcc(audio_samples_new_t[i])\n",
    "    audioDatasetFin_t.append((transformed_sample_t, labels_t[i]))\n",
    "    audioDatasetMfcc_t.append((transformed_sample_t, transformed_mfcc_t, labels_t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "189bbf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kat\\.conda\\envs\\tesis\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 1.3637, Train Accuracy: 0.3371, Val Accuracy: 0.5500, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3195, Train Accuracy: 0.3652, Val Accuracy: 0.2000, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.1827, Train Accuracy: 0.4944, Val Accuracy: 0.5000, Iter Time: 0.12s\n",
      "Epoch [20/100], Train Loss: 0.7311, Train Accuracy: 0.7191, Val Accuracy: 0.7500, Iter Time: 0.12s\n",
      "Epoch [25/100], Train Loss: 0.4818, Train Accuracy: 0.8258, Val Accuracy: 0.9000, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.4502, Train Accuracy: 0.8315, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.3115, Train Accuracy: 0.8708, Val Accuracy: 0.9000, Iter Time: 0.11s\n",
      "Early stopping after 36 epochs\n",
      "Fold 1 Best Validation Accuracy: 0.9000\n",
      "Fold 2/10\n",
      "Epoch [5/100], Train Loss: 1.3456, Train Accuracy: 0.3820, Val Accuracy: 0.3500, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3500, Train Accuracy: 0.3371, Val Accuracy: 0.5000, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.2005, Train Accuracy: 0.5787, Val Accuracy: 0.4500, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 0.8318, Train Accuracy: 0.6854, Val Accuracy: 0.7000, Iter Time: 0.12s\n",
      "Epoch [25/100], Train Loss: 0.7347, Train Accuracy: 0.6910, Val Accuracy: 0.7000, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.6121, Train Accuracy: 0.7640, Val Accuracy: 0.7000, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.5738, Train Accuracy: 0.7753, Val Accuracy: 0.7500, Iter Time: 0.12s\n",
      "Epoch [40/100], Train Loss: 0.4567, Train Accuracy: 0.8034, Val Accuracy: 0.8000, Iter Time: 0.12s\n",
      "Epoch [45/100], Train Loss: 0.4205, Train Accuracy: 0.8371, Val Accuracy: 0.8500, Iter Time: 0.12s\n",
      "Epoch [50/100], Train Loss: 0.3697, Train Accuracy: 0.8427, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Early stopping after 52 epochs\n",
      "Fold 2 Best Validation Accuracy: 0.8500\n",
      "Fold 3/10\n",
      "Epoch [5/100], Train Loss: 1.3330, Train Accuracy: 0.3876, Val Accuracy: 0.5000, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3207, Train Accuracy: 0.3820, Val Accuracy: 0.5000, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.2671, Train Accuracy: 0.4438, Val Accuracy: 0.8000, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 0.8170, Train Accuracy: 0.6236, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Epoch [25/100], Train Loss: 0.4732, Train Accuracy: 0.8371, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.3690, Train Accuracy: 0.8315, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.2540, Train Accuracy: 0.9045, Val Accuracy: 0.9500, Iter Time: 0.11s\n",
      "Epoch [40/100], Train Loss: 0.2802, Train Accuracy: 0.8596, Val Accuracy: 0.9000, Iter Time: 0.12s\n",
      "Epoch [45/100], Train Loss: 0.1646, Train Accuracy: 0.9663, Val Accuracy: 1.0000, Iter Time: 0.12s\n",
      "Epoch [50/100], Train Loss: 0.0986, Train Accuracy: 0.9831, Val Accuracy: 1.0000, Iter Time: 0.11s\n",
      "Early stopping after 53 epochs\n",
      "Fold 3 Best Validation Accuracy: 1.0000\n",
      "Fold 4/10\n",
      "Epoch [5/100], Train Loss: 1.2959, Train Accuracy: 0.3371, Val Accuracy: 0.2500, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3245, Train Accuracy: 0.3371, Val Accuracy: 0.2500, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.3183, Train Accuracy: 0.3876, Val Accuracy: 0.4500, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 1.2249, Train Accuracy: 0.4551, Val Accuracy: 0.3500, Iter Time: 0.11s\n",
      "Epoch [25/100], Train Loss: 0.9335, Train Accuracy: 0.6124, Val Accuracy: 0.5000, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.5353, Train Accuracy: 0.8090, Val Accuracy: 0.7000, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.3752, Train Accuracy: 0.8427, Val Accuracy: 0.7000, Iter Time: 0.11s\n",
      "Epoch [40/100], Train Loss: 0.3893, Train Accuracy: 0.8371, Val Accuracy: 0.7000, Iter Time: 0.11s\n",
      "Epoch [45/100], Train Loss: 0.3113, Train Accuracy: 0.8652, Val Accuracy: 0.7000, Iter Time: 0.11s\n",
      "Epoch [50/100], Train Loss: 0.3192, Train Accuracy: 0.8876, Val Accuracy: 0.7500, Iter Time: 0.12s\n",
      "Epoch [55/100], Train Loss: 0.2806, Train Accuracy: 0.8933, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Early stopping after 59 epochs\n",
      "Fold 4 Best Validation Accuracy: 0.9000\n",
      "Fold 5/10\n",
      "Epoch [5/100], Train Loss: 1.3703, Train Accuracy: 0.3820, Val Accuracy: 0.4000, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3121, Train Accuracy: 0.4101, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.1438, Train Accuracy: 0.5899, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 0.9737, Train Accuracy: 0.6011, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [25/100], Train Loss: 0.8243, Train Accuracy: 0.6517, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.8648, Train Accuracy: 0.6517, Val Accuracy: 0.8000, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.4882, Train Accuracy: 0.8258, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Epoch [40/100], Train Loss: 0.4243, Train Accuracy: 0.8258, Val Accuracy: 0.8000, Iter Time: 0.11s\n",
      "Epoch [45/100], Train Loss: 0.3832, Train Accuracy: 0.8427, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Early stopping after 46 epochs\n",
      "Fold 5 Best Validation Accuracy: 0.9000\n",
      "Fold 6/10\n",
      "Epoch [5/100], Train Loss: 1.3676, Train Accuracy: 0.3820, Val Accuracy: 0.2500, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3245, Train Accuracy: 0.3371, Val Accuracy: 0.6000, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.2483, Train Accuracy: 0.3820, Val Accuracy: 0.6000, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 0.8905, Train Accuracy: 0.6629, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [25/100], Train Loss: 0.5837, Train Accuracy: 0.7584, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.3912, Train Accuracy: 0.8427, Val Accuracy: 0.9000, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.2282, Train Accuracy: 0.9045, Val Accuracy: 1.0000, Iter Time: 0.11s\n",
      "Epoch [40/100], Train Loss: 0.2064, Train Accuracy: 0.9157, Val Accuracy: 0.9500, Iter Time: 0.11s\n",
      "Epoch [45/100], Train Loss: 0.1794, Train Accuracy: 0.9326, Val Accuracy: 1.0000, Iter Time: 0.11s\n",
      "Early stopping after 46 epochs\n",
      "Fold 6 Best Validation Accuracy: 1.0000\n",
      "Fold 7/10\n",
      "Epoch [5/100], Train Loss: 1.3860, Train Accuracy: 0.3933, Val Accuracy: 0.2500, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3556, Train Accuracy: 0.3933, Val Accuracy: 0.2500, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.1014, Train Accuracy: 0.5843, Val Accuracy: 0.8000, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 0.6924, Train Accuracy: 0.6742, Val Accuracy: 0.7500, Iter Time: 0.11s\n",
      "Epoch [25/100], Train Loss: 0.4252, Train Accuracy: 0.8202, Val Accuracy: 0.8000, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.3409, Train Accuracy: 0.8708, Val Accuracy: 0.8500, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.2848, Train Accuracy: 0.8933, Val Accuracy: 0.8000, Iter Time: 0.11s\n",
      "Early stopping after 36 epochs\n",
      "Fold 7 Best Validation Accuracy: 0.8500\n",
      "Fold 8/10\n",
      "Epoch [5/100], Train Loss: 1.3274, Train Accuracy: 0.3708, Val Accuracy: 0.1500, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3172, Train Accuracy: 0.2865, Val Accuracy: 0.4500, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.2423, Train Accuracy: 0.4157, Val Accuracy: 0.2000, Iter Time: 0.11s\n",
      "Early stopping after 16 epochs\n",
      "Fold 8 Best Validation Accuracy: 0.4500\n",
      "Fold 9/10\n",
      "Epoch [5/100], Train Loss: 1.3765, Train Accuracy: 0.3408, Val Accuracy: 0.5789, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3269, Train Accuracy: 0.3799, Val Accuracy: 0.2632, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.1694, Train Accuracy: 0.5810, Val Accuracy: 0.8421, Iter Time: 0.11s\n",
      "Epoch [20/100], Train Loss: 0.8618, Train Accuracy: 0.6425, Val Accuracy: 0.8421, Iter Time: 0.10s\n",
      "Epoch [25/100], Train Loss: 0.5959, Train Accuracy: 0.7654, Val Accuracy: 0.8421, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.4962, Train Accuracy: 0.8101, Val Accuracy: 0.8947, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.5070, Train Accuracy: 0.7821, Val Accuracy: 0.8947, Iter Time: 0.11s\n",
      "Epoch [40/100], Train Loss: 0.2995, Train Accuracy: 0.8827, Val Accuracy: 0.8947, Iter Time: 0.11s\n",
      "Early stopping after 43 epochs\n",
      "Fold 9 Best Validation Accuracy: 0.8947\n",
      "Fold 10/10\n",
      "Epoch [5/100], Train Loss: 1.3327, Train Accuracy: 0.3687, Val Accuracy: 0.2105, Iter Time: 0.11s\n",
      "Epoch [10/100], Train Loss: 1.3075, Train Accuracy: 0.3966, Val Accuracy: 0.2105, Iter Time: 0.11s\n",
      "Epoch [15/100], Train Loss: 1.0483, Train Accuracy: 0.7095, Val Accuracy: 0.5789, Iter Time: 0.10s\n",
      "Epoch [20/100], Train Loss: 0.4770, Train Accuracy: 0.8547, Val Accuracy: 0.6316, Iter Time: 0.11s\n",
      "Epoch [25/100], Train Loss: 0.3819, Train Accuracy: 0.8547, Val Accuracy: 0.6842, Iter Time: 0.11s\n",
      "Epoch [30/100], Train Loss: 0.2972, Train Accuracy: 0.8827, Val Accuracy: 0.7368, Iter Time: 0.11s\n",
      "Epoch [35/100], Train Loss: 0.2987, Train Accuracy: 0.8659, Val Accuracy: 0.7368, Iter Time: 0.11s\n",
      "Epoch [40/100], Train Loss: 0.2631, Train Accuracy: 0.8771, Val Accuracy: 0.7895, Iter Time: 0.12s\n",
      "Epoch [45/100], Train Loss: 0.1797, Train Accuracy: 0.9274, Val Accuracy: 0.8947, Iter Time: 0.12s\n",
      "Epoch [50/100], Train Loss: 0.1984, Train Accuracy: 0.9050, Val Accuracy: 0.9474, Iter Time: 0.11s\n",
      "Epoch [55/100], Train Loss: 0.1532, Train Accuracy: 0.9330, Val Accuracy: 0.9474, Iter Time: 0.11s\n",
      "Early stopping after 59 epochs\n",
      "Fold 10 Best Validation Accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "#Using custom audio:\n",
    "# current random state to split the dataset\n",
    "random_state = 42\n",
    "\n",
    "# values for current run\n",
    "train_final_set, test_set = train_test_split(audioDatasetMfcc_t, test_size=0.2, random_state=random_state)\n",
    "num_epochs = 100\n",
    "main_architecture = \"CNN_LSTM\"\n",
    "currday = datetime.today().strftime('%Y-%m-%d')\n",
    "model_name = f\"model_multiclass_custom_audio_{num_epochs}_{main_architecture}_{currday}.pth\"\n",
    "description = \"2 layer CNN (32 and 64 output channels) with final 2 Dense Layers (512 and num_classes) result concatenated with \\n 2 LSTMs (hidden_size=32),  from mfcc with 2 Dense Layers (64 and 16) with a final Lazy Linear layer output of num_classes. \\n Using custom audio recorded for testing purposes.\"\n",
    "\n",
    "# Training part\n",
    "fold_stats = train_with_cross_validation(train_final_set, num_epochs, model_name, random_state=random_state)\n",
    "max_val = 0\n",
    "real_num_epochs = 0\n",
    "for fold_stat in fold_stats: #using folds instead of LOO\n",
    "    if fold_stat[1] > max_val:\n",
    "        max_val = fold_stat[1]\n",
    "        real_num_epochs = fold_stat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859fa190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction part\n",
    "prediction = predict_mfcc(test_set, model_name, device) #using the custom test_set\n",
    "labels_set = [t[2] for t in test_set]\n",
    "print(labels_set)\n",
    "print(prediction[0])\n",
    "final_labels_set = [keys_t_s[ind] for ind in labels_set]\n",
    "\n",
    "# Metrics calculation\n",
    "accuracy = accuracy_score(final_labels_set, prediction[0])\n",
    "precision = precision_score(final_labels_set, prediction[0], average='macro')\n",
    "recall = recall_score(final_labels_set, prediction[0], average='macro')\n",
    "f1 = sklearn.metrics.f1_score(final_labels_set, prediction[0], average='macro')\n",
    "\n",
    "# Save in csv file\n",
    "save_csv(model_name, real_num_epochs, description, accuracy, precision, recall, f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Final Results!\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(description)\n",
    "print(f\"Epochs: {real_num_epochs}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
