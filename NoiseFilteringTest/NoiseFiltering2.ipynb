{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak identification test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the audio files all have 40 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1.wav length: 41\n",
      "File 2.wav length: 40\n",
      "File 3.wav length: 40\n",
      "File 4.wav length: 40\n",
      "File 5.wav length: 40\n",
      "File 6.wav length: 40\n",
      "File 7.wav length: 40\n",
      "File 8.wav length: 40\n",
      "File 9.wav length: 40\n",
      "File 0.wav length: 40\n",
      "File A.wav length: 40\n",
      "File B.wav length: 40\n",
      "File C.wav length: 40\n",
      "File D.wav length: 40\n",
      "File E.wav length: 40\n",
      "File F.wav length: 40\n",
      "File G.wav length: 40\n",
      "File H.wav length: 41\n",
      "File I.wav length: 40\n",
      "File J.wav length: 40\n",
      "File K.wav length: 40\n",
      "File L.wav length: 41\n",
      "File M.wav length: 40\n",
      "File N.wav length: 40\n",
      "File Ñ.wav length: 40\n",
      "File O.wav length: 40\n",
      "File P.wav length: 40\n",
      "File Q.wav length: 40\n",
      "File R.wav length: 40\n",
      "File S.wav length: 40\n",
      "File T.wav length: 40\n",
      "File U.wav length: 40\n",
      "File V.wav length: 40\n",
      "File W.wav length: 40\n",
      "File X.wav length: 39\n",
      "File Y.wav length: 40\n",
      "File Z.wav length: 40\n",
      "File +.wav length: 40\n",
      "File -.wav length: 40\n",
      "isolator results:35/40\n"
     ]
    }
   ],
   "source": [
    "# method 1: isolator\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# waveform function for me to not bang my keyboard\n",
    "def disp_waveform(signal, sr=None, color='blue'):\n",
    "    plt.figure(figsize=(7,2))\n",
    "    return librosa.display.waveshow(signal, sr=sr, color=color)\n",
    "\n",
    "def isolator(signal, sample_rate, n_fft, hop_length, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        disp_waveform(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        disp_waveform(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        disp_waveform(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*hop_length) + n_fft//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            # strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            # keystroke = transform(keystroke)\n",
    "            strokes.append(keystroke)\n",
    "            if show:\n",
    "                disp_waveform(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes\n",
    "\n",
    "def create_dataset(n_fft, hop_length, before, after, keys, audio_dir):\n",
    "    result=[]\n",
    "    for i, File in enumerate(keys):\n",
    "        loc = audio_dir + File\n",
    "        samples, sr = librosa.load(loc)\n",
    "        prom = 0.005 #0.06\n",
    "        step = 0.005\n",
    "        strokes = isolator(samples, sr, n_fft, hop_length, before, after, prom, False )\n",
    "        print(f'File {File} length: {len(strokes)}')\n",
    "        if len(strokes) == 40:\n",
    "            result.append(strokes)\n",
    "    return result\n",
    "\n",
    "\n",
    "keys_s = '1234567890ABCDEFGHIJKLMNÑOPQRSTUVWXYZ+-' \n",
    "labels = list(keys_s)\n",
    "keys = [ k + '.wav' for k in labels] \n",
    "MBP_AUDIO_DIR = '../Dataset-custom-audio/base-audio-denoised-normalized/'\n",
    "result_isolator=create_dataset(22550, 22550, 2400, 12000, keys, MBP_AUDIO_DIR)\n",
    "print(\"isolator results:\"+str(len(result_isolator))+\"/40\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
